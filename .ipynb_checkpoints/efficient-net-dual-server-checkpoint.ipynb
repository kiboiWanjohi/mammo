{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# # This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# # It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# # For example, here's several helpful packages to load\n",
    "\n",
    "# import numpy as np # linear algebra\n",
    "# import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# # Input data files are available in the read-only \"../input/\" directory\n",
    "# # For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "# import os\n",
    "# for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "#     for filename in filenames:\n",
    "#         print(os.path.join(dirname, filename))\n",
    "\n",
    "# # You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# # You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "current_working_directory = os.getcwd()\n",
    "\n",
    "# print output to the console\n",
    "print(current_working_directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-10T12:50:50.042451Z",
     "iopub.status.busy": "2025-06-10T12:50:50.042127Z",
     "iopub.status.idle": "2025-06-10T12:50:55.038204Z",
     "shell.execute_reply": "2025-06-10T12:50:55.037183Z",
     "shell.execute_reply.started": "2025-06-10T12:50:50.042422Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-10 12:50:50.920550: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1749559850.949252     281 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1749559850.962062     281 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "# necessary libraries \n",
    "import os\n",
    "import PIL\n",
    "import cv2\n",
    "import uuid\n",
    "import shutil\n",
    "import random\n",
    "import glob as gb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from PIL import Image\n",
    "from tqdm import tqdm  # Progress bar\n",
    "from scipy.special import gamma\n",
    "\n",
    "from keras.optimizers import *\n",
    "from keras.regularizers import l1_l2\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Input\n",
    "from keras.layers import GlobalAveragePooling2D, Concatenate\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras.layers import Conv2D, MaxPool2D, BatchNormalization\n",
    "\n",
    "from tensorflow.keras.metrics import *\n",
    "from tensorflow.keras.callbacks import *\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-10T12:50:55.040711Z",
     "iopub.status.busy": "2025-06-10T12:50:55.039998Z",
     "iopub.status.idle": "2025-06-10T12:50:55.290138Z",
     "shell.execute_reply": "2025-06-10T12:50:55.289224Z",
     "shell.execute_reply.started": "2025-06-10T12:50:55.040681Z"
    }
   },
   "outputs": [],
   "source": [
    "calc_train = pd.read_csv('/kaggle/input/cbis-ddsm-breast-cancer-image-dataset/csv/calc_case_description_train_set.csv')\n",
    "calc_test = pd.read_csv('/kaggle/input/cbis-ddsm-breast-cancer-image-dataset/csv/calc_case_description_test_set.csv')\n",
    "mass_train = pd.read_csv('/kaggle/input/cbis-ddsm-breast-cancer-image-dataset/csv/mass_case_description_train_set.csv')\n",
    "mass_test = pd.read_csv('/kaggle/input/cbis-ddsm-breast-cancer-image-dataset/csv/mass_case_description_test_set.csv')\n",
    "dicom_df = pd.read_csv('/kaggle/input/cbis-ddsm-breast-cancer-image-dataset/csv/dicom_info.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-10T12:50:56.674014Z",
     "iopub.status.busy": "2025-06-10T12:50:56.673634Z",
     "iopub.status.idle": "2025-06-10T12:50:56.679776Z",
     "shell.execute_reply": "2025-06-10T12:50:56.678477Z",
     "shell.execute_reply.started": "2025-06-10T12:50:56.673989Z"
    }
   },
   "outputs": [],
   "source": [
    "def replace_path(sample, old_path, new_path):\n",
    "    return sample.replace(old_path, new_path, regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-10T12:50:59.522296Z",
     "iopub.status.busy": "2025-06-10T12:50:59.521614Z",
     "iopub.status.idle": "2025-06-10T12:50:59.528176Z",
     "shell.execute_reply": "2025-06-10T12:50:59.527176Z",
     "shell.execute_reply.started": "2025-06-10T12:50:59.522270Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_smaples(sample, row=15, col=15):\n",
    "    plt.figure(figsize=(row, col))\n",
    "    for i, file in enumerate(sample[0:5]):\n",
    "        cropped_images_show = PIL.Image.open(file)\n",
    "        gray_img= cropped_images_show.convert(\"L\")\n",
    "        plt.subplot(1,5,i+1)\n",
    "        plt.imshow(gray_img, cmap='gray')\n",
    "        plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Filter for patients with both CC and MLO views\n",
    "# def get_paired_samples(df):\n",
    "#     # Group by patient_id and ensure both CC and MLO views exist\n",
    "#     grouped = df.groupby('patient_id').filter(lambda x: set(x['image_view']) == {'CC', 'MLO'})\n",
    "#     return grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Filter for patients with exactly one CC and one MLO view\n",
    "# def get_paired_samples(df):\n",
    "#     # Group by patient_id and ensure both CC and MLO views exist\n",
    "#     grouped = df.groupby('patient_id').filter(lambda x: set(x['image_view']) == {'CC', 'MLO'})\n",
    "    \n",
    "#     # For each patient, select one CC and one MLO view (e.g., first occurrence)\n",
    "#     cc_views = grouped[grouped['image_view'] == 'CC'].groupby('patient_id').first().reset_index()\n",
    "#     mlo_views = grouped[grouped['image_view'] == 'MLO'].groupby('patient_id').first().reset_index()\n",
    "    \n",
    "#     # Ensure only patients present in both CC and MLO are kept\n",
    "#     common_patients = np.intersect1d(cc_views['patient_id'], mlo_views['patient_id'])\n",
    "#     cc_views = cc_views[cc_views['patient_id'].isin(common_patients)].sort_values('patient_id').reset_index(drop=True)\n",
    "#     mlo_views = mlo_views[mlo_views['patient_id'].isin(common_patients)].sort_values('patient_id').reset_index(drop=True)\n",
    "    \n",
    "#     return cc_views, mlo_views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-10T12:51:24.629888Z",
     "iopub.status.busy": "2025-06-10T12:51:24.629534Z",
     "iopub.status.idle": "2025-06-10T12:51:24.649685Z",
     "shell.execute_reply": "2025-06-10T12:51:24.648406Z",
     "shell.execute_reply.started": "2025-06-10T12:51:24.629863Z"
    }
   },
   "outputs": [],
   "source": [
    "cropped_images = dicom_df[dicom_df.SeriesDescription==\"cropped images\"].image_path\n",
    "full_mammogram = dicom_df[dicom_df.SeriesDescription==\"full mammogram images\"].image_path\n",
    "roi_mask = dicom_df[dicom_df.SeriesDescription==\"ROI mask images\"].image_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-10T12:51:27.390210Z",
     "iopub.status.busy": "2025-06-10T12:51:27.389385Z",
     "iopub.status.idle": "2025-06-10T12:51:27.396902Z",
     "shell.execute_reply": "2025-06-10T12:51:27.395786Z",
     "shell.execute_reply.started": "2025-06-10T12:51:27.390173Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cropped Image Path:  CBIS-DDSM/jpeg/1.3.6.1.4.1.9590.100.1.2.129308726812851964007517874181459556304/1-172.jpg\n",
      "FULL Mammogram Path:  CBIS-DDSM/jpeg/1.3.6.1.4.1.9590.100.1.2.248386742010678582309005372213277814849/1-249.jpg\n",
      "ROI MASK Path:  CBIS-DDSM/jpeg/1.3.6.1.4.1.9590.100.1.2.153339052913121382622526066491844156138/2-270.jpg\n"
     ]
    }
   ],
   "source": [
    "# check paths\n",
    "print(\"Cropped Image Path: \", cropped_images.iloc[0])\n",
    "print(\"FULL Mammogram Path: \", full_mammogram.iloc[0])\n",
    "print(\"ROI MASK Path: \", roi_mask.iloc[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-10T12:51:30.842632Z",
     "iopub.status.busy": "2025-06-10T12:51:30.842305Z",
     "iopub.status.idle": "2025-06-10T12:51:30.861090Z",
     "shell.execute_reply": "2025-06-10T12:51:30.859966Z",
     "shell.execute_reply.started": "2025-06-10T12:51:30.842608Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cropped Images paths:\n",
      "../input/cbis-ddsm-breast-cancer-image-dataset/jpeg/1.3.6.1.4.1.9590.100.1.2.129308726812851964007517874181459556304/1-172.jpg\n",
      "\n",
      "Full mammo Images paths:\n",
      "../input/cbis-ddsm-breast-cancer-image-dataset/jpeg/1.3.6.1.4.1.9590.100.1.2.248386742010678582309005372213277814849/1-249.jpg\n",
      "\n",
      "ROI Mask Images paths:\n",
      "../input/cbis-ddsm-breast-cancer-image-dataset/jpeg/1.3.6.1.4.1.9590.100.1.2.153339052913121382622526066491844156138/2-270.jpg\n"
     ]
    }
   ],
   "source": [
    "# Replace the path for cropped_images to the correct directory.\n",
    "correct_dir = \"../input/cbis-ddsm-breast-cancer-image-dataset/jpeg\"\n",
    "cropped_images = replace_path(cropped_images, \"CBIS-DDSM/jpeg\", correct_dir)\n",
    "print('Cropped Images paths:')\n",
    "print(cropped_images.iloc[0]) # Print to ensure everything looks correct.\n",
    "\n",
    "\n",
    "# Replace the path for full_mammogram images to the correct directory.\n",
    "full_mammogram = replace_path(full_mammogram, \"CBIS-DDSM/jpeg\", correct_dir)\n",
    "print('\\nFull mammo Images paths:')\n",
    "print(full_mammogram.iloc[0]) # Print to ensure everything looks correct.\n",
    "\n",
    "# Replace the path for roi_mask images to the correct directory.\n",
    "roi_mask = replace_path(roi_mask, \"CBIS-DDSM/jpeg\", correct_dir)\n",
    "print('\\nROI Mask Images paths:')\n",
    "print(roi_mask.iloc[0]) # Print to ensure everything looks correct.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-10T12:51:42.897429Z",
     "iopub.status.busy": "2025-06-10T12:51:42.897090Z",
     "iopub.status.idle": "2025-06-10T12:51:42.917982Z",
     "shell.execute_reply": "2025-06-10T12:51:42.916931Z",
     "shell.execute_reply.started": "2025-06-10T12:51:42.897407Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the length of dataset ==> 3567\n",
      "the length of dataset ==> 2857\n",
      "the length of dataset ==> 3247\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('1.3.6.1.4.1.9590.100.1.2.153339052913121382622526066491844156138',\n",
       "  '../input/cbis-ddsm-breast-cancer-image-dataset/jpeg/1.3.6.1.4.1.9590.100.1.2.153339052913121382622526066491844156138/2-270.jpg'),\n",
       " ('1.3.6.1.4.1.9590.100.1.2.178994714611485132105265512043047466091',\n",
       "  '../input/cbis-ddsm-breast-cancer-image-dataset/jpeg/1.3.6.1.4.1.9590.100.1.2.178994714611485132105265512043047466091/2-127.jpg'),\n",
       " ('1.3.6.1.4.1.9590.100.1.2.411833492612373627114350673042828631265',\n",
       "  '../input/cbis-ddsm-breast-cancer-image-dataset/jpeg/1.3.6.1.4.1.9590.100.1.2.411833492612373627114350673042828631265/2-281.jpg'),\n",
       " ('1.3.6.1.4.1.9590.100.1.2.236373548712994183418851990043419770402',\n",
       "  '../input/cbis-ddsm-breast-cancer-image-dataset/jpeg/1.3.6.1.4.1.9590.100.1.2.236373548712994183418851990043419770402/2-086.jpg'),\n",
       " ('1.3.6.1.4.1.9590.100.1.2.357008050412534761329866492500201501919',\n",
       "  '../input/cbis-ddsm-breast-cancer-image-dataset/jpeg/1.3.6.1.4.1.9590.100.1.2.357008050412534761329866492500201501919/1-241.jpg')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_image_file_name(data, new_dict):\n",
    "\n",
    "    for dicom in data:\n",
    "        key = dicom.split('/')[4]\n",
    "        new_dict[key] = dicom\n",
    "    print(f\"the length of dataset ==> {len(new_dict.keys())}\")\n",
    "\n",
    "\n",
    "cropped_images_dict = dict()\n",
    "full_mammo_dict = dict()\n",
    "roi_img_dict = dict()\n",
    "\n",
    "get_image_file_name(cropped_images, cropped_images_dict)\n",
    "get_image_file_name(full_mammogram, full_mammo_dict)\n",
    "get_image_file_name(roi_mask, roi_img_dict)\n",
    "\n",
    "\n",
    "\n",
    "list(cropped_images_dict.items())[:5]\n",
    "\n",
    "\n",
    "list(full_mammo_dict.items())[:5]\n",
    "\n",
    "list(roi_img_dict.items())[:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-10T12:51:45.870680Z",
     "iopub.status.busy": "2025-06-10T12:51:45.870292Z",
     "iopub.status.idle": "2025-06-10T12:51:45.877642Z",
     "shell.execute_reply": "2025-06-10T12:51:45.876518Z",
     "shell.execute_reply.started": "2025-06-10T12:51:45.870654Z"
    }
   },
   "outputs": [],
   "source": [
    "def fix_image_path_mass(dataset):\n",
    "    for i, img in enumerate(dataset.values):\n",
    "        img_name = img[11].split(\"/\")[2]\n",
    "        if img_name in full_mammo_dict:\n",
    "            dataset.iloc[i, 11] = full_mammo_dict[img_name]\n",
    "\n",
    "        img_name = img[12].split(\"/\")[2]\n",
    "        if img_name in cropped_images_dict:\n",
    "            dataset.iloc[i, 12] = cropped_images_dict[img_name]\n",
    "\n",
    "        img_name = img[13].split(\"/\")[2]\n",
    "        if img_name in roi_img_dict:\n",
    "            dataset.iloc[i, 13] = roi_img_dict[img_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-10T12:51:51.692449Z",
     "iopub.status.busy": "2025-06-10T12:51:51.692048Z",
     "iopub.status.idle": "2025-06-10T12:51:52.382129Z",
     "shell.execute_reply": "2025-06-10T12:51:52.381287Z",
     "shell.execute_reply.started": "2025-06-10T12:51:51.692421Z"
    }
   },
   "outputs": [],
   "source": [
    "fix_image_path_mass(mass_train)\n",
    "fix_image_path_mass(mass_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-10T12:51:53.527349Z",
     "iopub.status.busy": "2025-06-10T12:51:53.526478Z",
     "iopub.status.idle": "2025-06-10T12:51:53.547423Z",
     "shell.execute_reply": "2025-06-10T12:51:53.546028Z",
     "shell.execute_reply.started": "2025-06-10T12:51:53.527318Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>breast_density</th>\n",
       "      <th>left_or_right_breast</th>\n",
       "      <th>image_view</th>\n",
       "      <th>abnormality_id</th>\n",
       "      <th>abnormality_type</th>\n",
       "      <th>mass_shape</th>\n",
       "      <th>mass_margins</th>\n",
       "      <th>assessment</th>\n",
       "      <th>pathology</th>\n",
       "      <th>subtlety</th>\n",
       "      <th>image_file_path</th>\n",
       "      <th>cropped_image_file_path</th>\n",
       "      <th>ROI_mask_file_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P_00001</td>\n",
       "      <td>3</td>\n",
       "      <td>LEFT</td>\n",
       "      <td>CC</td>\n",
       "      <td>1</td>\n",
       "      <td>mass</td>\n",
       "      <td>IRREGULAR-ARCHITECTURAL_DISTORTION</td>\n",
       "      <td>SPICULATED</td>\n",
       "      <td>4</td>\n",
       "      <td>MALIGNANT</td>\n",
       "      <td>4</td>\n",
       "      <td>../input/cbis-ddsm-breast-cancer-image-dataset...</td>\n",
       "      <td>../input/cbis-ddsm-breast-cancer-image-dataset...</td>\n",
       "      <td>../input/cbis-ddsm-breast-cancer-image-dataset...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P_00001</td>\n",
       "      <td>3</td>\n",
       "      <td>LEFT</td>\n",
       "      <td>MLO</td>\n",
       "      <td>1</td>\n",
       "      <td>mass</td>\n",
       "      <td>IRREGULAR-ARCHITECTURAL_DISTORTION</td>\n",
       "      <td>SPICULATED</td>\n",
       "      <td>4</td>\n",
       "      <td>MALIGNANT</td>\n",
       "      <td>4</td>\n",
       "      <td>../input/cbis-ddsm-breast-cancer-image-dataset...</td>\n",
       "      <td>../input/cbis-ddsm-breast-cancer-image-dataset...</td>\n",
       "      <td>../input/cbis-ddsm-breast-cancer-image-dataset...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P_00004</td>\n",
       "      <td>3</td>\n",
       "      <td>LEFT</td>\n",
       "      <td>CC</td>\n",
       "      <td>1</td>\n",
       "      <td>mass</td>\n",
       "      <td>ARCHITECTURAL_DISTORTION</td>\n",
       "      <td>ILL_DEFINED</td>\n",
       "      <td>4</td>\n",
       "      <td>BENIGN</td>\n",
       "      <td>3</td>\n",
       "      <td>../input/cbis-ddsm-breast-cancer-image-dataset...</td>\n",
       "      <td>../input/cbis-ddsm-breast-cancer-image-dataset...</td>\n",
       "      <td>../input/cbis-ddsm-breast-cancer-image-dataset...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  patient_id  breast_density left_or_right_breast image_view  abnormality_id  \\\n",
       "0    P_00001               3                 LEFT         CC               1   \n",
       "1    P_00001               3                 LEFT        MLO               1   \n",
       "2    P_00004               3                 LEFT         CC               1   \n",
       "\n",
       "  abnormality_type                          mass_shape mass_margins  \\\n",
       "0             mass  IRREGULAR-ARCHITECTURAL_DISTORTION   SPICULATED   \n",
       "1             mass  IRREGULAR-ARCHITECTURAL_DISTORTION   SPICULATED   \n",
       "2             mass            ARCHITECTURAL_DISTORTION  ILL_DEFINED   \n",
       "\n",
       "   assessment  pathology  subtlety  \\\n",
       "0           4  MALIGNANT         4   \n",
       "1           4  MALIGNANT         4   \n",
       "2           4     BENIGN         3   \n",
       "\n",
       "                                     image_file_path  \\\n",
       "0  ../input/cbis-ddsm-breast-cancer-image-dataset...   \n",
       "1  ../input/cbis-ddsm-breast-cancer-image-dataset...   \n",
       "2  ../input/cbis-ddsm-breast-cancer-image-dataset...   \n",
       "\n",
       "                             cropped_image_file_path  \\\n",
       "0  ../input/cbis-ddsm-breast-cancer-image-dataset...   \n",
       "1  ../input/cbis-ddsm-breast-cancer-image-dataset...   \n",
       "2  ../input/cbis-ddsm-breast-cancer-image-dataset...   \n",
       "\n",
       "                                  ROI_mask_file_path  \n",
       "0  ../input/cbis-ddsm-breast-cancer-image-dataset...  \n",
       "1  ../input/cbis-ddsm-breast-cancer-image-dataset...  \n",
       "2  ../input/cbis-ddsm-breast-cancer-image-dataset...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mass_train = mass_train.rename(columns={'left or right breast': 'left_or_right_breast',\n",
    "                                        'image view': 'image_view',\n",
    "                                        'abnormality id': 'abnormality_id',\n",
    "                                        'abnormality type': 'abnormality_type',\n",
    "                                        'mass shape': 'mass_shape',\n",
    "                                        'mass margins': 'mass_margins',\n",
    "                                        'image file path': 'image_file_path',\n",
    "                                        'cropped image file path': 'cropped_image_file_path',\n",
    "                                        'ROI mask file path': 'ROI_mask_file_path'})\n",
    "# view renamed columns \n",
    "mass_train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-10T12:51:55.850393Z",
     "iopub.status.busy": "2025-06-10T12:51:55.850001Z",
     "iopub.status.idle": "2025-06-10T12:51:55.867768Z",
     "shell.execute_reply": "2025-06-10T12:51:55.866773Z",
     "shell.execute_reply.started": "2025-06-10T12:51:55.850366Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>breast_density</th>\n",
       "      <th>left_or_right_breast</th>\n",
       "      <th>image_view</th>\n",
       "      <th>abnormality_id</th>\n",
       "      <th>abnormality_type</th>\n",
       "      <th>mass_shape</th>\n",
       "      <th>mass_margins</th>\n",
       "      <th>assessment</th>\n",
       "      <th>pathology</th>\n",
       "      <th>subtlety</th>\n",
       "      <th>image_file_path</th>\n",
       "      <th>cropped_image_file_path</th>\n",
       "      <th>ROI_mask_file_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P_00016</td>\n",
       "      <td>4</td>\n",
       "      <td>LEFT</td>\n",
       "      <td>CC</td>\n",
       "      <td>1</td>\n",
       "      <td>mass</td>\n",
       "      <td>IRREGULAR</td>\n",
       "      <td>SPICULATED</td>\n",
       "      <td>5</td>\n",
       "      <td>MALIGNANT</td>\n",
       "      <td>5</td>\n",
       "      <td>../input/cbis-ddsm-breast-cancer-image-dataset...</td>\n",
       "      <td>../input/cbis-ddsm-breast-cancer-image-dataset...</td>\n",
       "      <td>../input/cbis-ddsm-breast-cancer-image-dataset...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P_00016</td>\n",
       "      <td>4</td>\n",
       "      <td>LEFT</td>\n",
       "      <td>MLO</td>\n",
       "      <td>1</td>\n",
       "      <td>mass</td>\n",
       "      <td>IRREGULAR</td>\n",
       "      <td>SPICULATED</td>\n",
       "      <td>5</td>\n",
       "      <td>MALIGNANT</td>\n",
       "      <td>5</td>\n",
       "      <td>../input/cbis-ddsm-breast-cancer-image-dataset...</td>\n",
       "      <td>../input/cbis-ddsm-breast-cancer-image-dataset...</td>\n",
       "      <td>../input/cbis-ddsm-breast-cancer-image-dataset...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P_00017</td>\n",
       "      <td>2</td>\n",
       "      <td>LEFT</td>\n",
       "      <td>CC</td>\n",
       "      <td>1</td>\n",
       "      <td>mass</td>\n",
       "      <td>ROUND</td>\n",
       "      <td>CIRCUMSCRIBED</td>\n",
       "      <td>4</td>\n",
       "      <td>MALIGNANT</td>\n",
       "      <td>4</td>\n",
       "      <td>../input/cbis-ddsm-breast-cancer-image-dataset...</td>\n",
       "      <td>../input/cbis-ddsm-breast-cancer-image-dataset...</td>\n",
       "      <td>../input/cbis-ddsm-breast-cancer-image-dataset...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  patient_id  breast_density left_or_right_breast image_view  abnormality_id  \\\n",
       "0    P_00016               4                 LEFT         CC               1   \n",
       "1    P_00016               4                 LEFT        MLO               1   \n",
       "2    P_00017               2                 LEFT         CC               1   \n",
       "\n",
       "  abnormality_type mass_shape   mass_margins  assessment  pathology  subtlety  \\\n",
       "0             mass  IRREGULAR     SPICULATED           5  MALIGNANT         5   \n",
       "1             mass  IRREGULAR     SPICULATED           5  MALIGNANT         5   \n",
       "2             mass      ROUND  CIRCUMSCRIBED           4  MALIGNANT         4   \n",
       "\n",
       "                                     image_file_path  \\\n",
       "0  ../input/cbis-ddsm-breast-cancer-image-dataset...   \n",
       "1  ../input/cbis-ddsm-breast-cancer-image-dataset...   \n",
       "2  ../input/cbis-ddsm-breast-cancer-image-dataset...   \n",
       "\n",
       "                             cropped_image_file_path  \\\n",
       "0  ../input/cbis-ddsm-breast-cancer-image-dataset...   \n",
       "1  ../input/cbis-ddsm-breast-cancer-image-dataset...   \n",
       "2  ../input/cbis-ddsm-breast-cancer-image-dataset...   \n",
       "\n",
       "                                  ROI_mask_file_path  \n",
       "0  ../input/cbis-ddsm-breast-cancer-image-dataset...  \n",
       "1  ../input/cbis-ddsm-breast-cancer-image-dataset...  \n",
       "2  ../input/cbis-ddsm-breast-cancer-image-dataset...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mass_test = mass_test.rename(columns={'left or right breast': 'left_or_right_breast',\n",
    "                                        'image view': 'image_view',\n",
    "                                        'abnormality id': 'abnormality_id',\n",
    "                                        'abnormality type': 'abnormality_type',\n",
    "                                        'mass shape': 'mass_shape',\n",
    "                                        'mass margins': 'mass_margins',\n",
    "                                        'image file path': 'image_file_path',\n",
    "                                        'cropped image file path': 'cropped_image_file_path',\n",
    "                                        'ROI mask file path': 'ROI_mask_file_path'})\n",
    "# view renamed columns \n",
    "mass_test.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-10T12:51:58.827627Z",
     "iopub.status.busy": "2025-06-10T12:51:58.827316Z",
     "iopub.status.idle": "2025-06-10T12:51:58.835024Z",
     "shell.execute_reply": "2025-06-10T12:51:58.833970Z",
     "shell.execute_reply.started": "2025-06-10T12:51:58.827606Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['MALIGNANT', 'BENIGN', 'BENIGN_WITHOUT_CALLBACK'], dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mass_train.pathology.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-10T12:52:02.582782Z",
     "iopub.status.busy": "2025-06-10T12:52:02.582478Z",
     "iopub.status.idle": "2025-06-10T12:52:02.589518Z",
     "shell.execute_reply": "2025-06-10T12:52:02.588623Z",
     "shell.execute_reply.started": "2025-06-10T12:52:02.582762Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['MALIGNANT', 'BENIGN', 'BENIGN_WITHOUT_CALLBACK'], dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "mass_test.pathology.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-10T12:52:04.277104Z",
     "iopub.status.busy": "2025-06-10T12:52:04.276687Z",
     "iopub.status.idle": "2025-06-10T12:52:04.283919Z",
     "shell.execute_reply": "2025-06-10T12:52:04.282821Z",
     "shell.execute_reply.started": "2025-06-10T12:52:04.277076Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../input/cbis-ddsm-breast-cancer-image-dataset/jpeg/1.3.6.1.4.1.9590.100.1.2.342386194811267636608694132590482924515/1-211.jpg'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mass_train.image_file_path[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-10T12:52:06.968599Z",
     "iopub.status.busy": "2025-06-10T12:52:06.968239Z",
     "iopub.status.idle": "2025-06-10T12:52:06.976552Z",
     "shell.execute_reply": "2025-06-10T12:52:06.975294Z",
     "shell.execute_reply.started": "2025-06-10T12:52:06.968577Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../input/cbis-ddsm-breast-cancer-image-dataset/jpeg/1.3.6.1.4.1.9590.100.1.2.245063149211255120613007755642780114172/1-271.jpg'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mass_test.image_file_path[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-10T12:52:09.431592Z",
     "iopub.status.busy": "2025-06-10T12:52:09.431228Z",
     "iopub.status.idle": "2025-06-10T12:52:09.443228Z",
     "shell.execute_reply": "2025-06-10T12:52:09.442031Z",
     "shell.execute_reply.started": "2025-06-10T12:52:09.431568Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_file_path</th>\n",
       "      <th>image_view</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../input/cbis-ddsm-breast-cancer-image-dataset...</td>\n",
       "      <td>CC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../input/cbis-ddsm-breast-cancer-image-dataset...</td>\n",
       "      <td>MLO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../input/cbis-ddsm-breast-cancer-image-dataset...</td>\n",
       "      <td>CC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../input/cbis-ddsm-breast-cancer-image-dataset...</td>\n",
       "      <td>MLO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../input/cbis-ddsm-breast-cancer-image-dataset...</td>\n",
       "      <td>MLO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     image_file_path image_view\n",
       "0  ../input/cbis-ddsm-breast-cancer-image-dataset...         CC\n",
       "1  ../input/cbis-ddsm-breast-cancer-image-dataset...        MLO\n",
       "2  ../input/cbis-ddsm-breast-cancer-image-dataset...         CC\n",
       "3  ../input/cbis-ddsm-breast-cancer-image-dataset...        MLO\n",
       "4  ../input/cbis-ddsm-breast-cancer-image-dataset...        MLO"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mass_train[['image_file_path', 'image_view']].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-10T12:52:15.317789Z",
     "iopub.status.busy": "2025-06-10T12:52:15.317269Z",
     "iopub.status.idle": "2025-06-10T12:52:15.329334Z",
     "shell.execute_reply": "2025-06-10T12:52:15.328218Z",
     "shell.execute_reply.started": "2025-06-10T12:52:15.317750Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_file_path</th>\n",
       "      <th>image_view</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../input/cbis-ddsm-breast-cancer-image-dataset...</td>\n",
       "      <td>CC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../input/cbis-ddsm-breast-cancer-image-dataset...</td>\n",
       "      <td>MLO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../input/cbis-ddsm-breast-cancer-image-dataset...</td>\n",
       "      <td>CC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../input/cbis-ddsm-breast-cancer-image-dataset...</td>\n",
       "      <td>MLO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../input/cbis-ddsm-breast-cancer-image-dataset...</td>\n",
       "      <td>CC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     image_file_path image_view\n",
       "0  ../input/cbis-ddsm-breast-cancer-image-dataset...         CC\n",
       "1  ../input/cbis-ddsm-breast-cancer-image-dataset...        MLO\n",
       "2  ../input/cbis-ddsm-breast-cancer-image-dataset...         CC\n",
       "3  ../input/cbis-ddsm-breast-cancer-image-dataset...        MLO\n",
       "4  ../input/cbis-ddsm-breast-cancer-image-dataset...         CC"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mass_test[['image_file_path', 'image_view']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-10T12:52:21.888515Z",
     "iopub.status.busy": "2025-06-10T12:52:21.888126Z",
     "iopub.status.idle": "2025-06-10T12:52:21.998194Z",
     "shell.execute_reply": "2025-06-10T12:52:21.997086Z",
     "shell.execute_reply.started": "2025-06-10T12:52:21.888489Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train CC samples: 490\n",
      "Train MLO samples: 490\n",
      "Test CC samples: 146\n",
      "Test MLO samples: 146\n",
      "✅ All alignment checks passed!\n",
      "\n",
      "Training patients with paired CC/MLO views: 490\n",
      "Testing patients with paired CC/MLO views: 146\n",
      "\n",
      "--- Sample of aligned training data ---\n",
      "CC views:\n",
      "  patient_id image_view  pathology\n",
      "0    P_00001         CC  MALIGNANT\n",
      "1    P_00004         CC     BENIGN\n",
      "2    P_00009         CC  MALIGNANT\n",
      "3    P_00018         CC     BENIGN\n",
      "4    P_00021         CC     BENIGN\n",
      "\n",
      "MLO views:\n",
      "  patient_id image_view  pathology\n",
      "0    P_00001        MLO  MALIGNANT\n",
      "1    P_00004        MLO     BENIGN\n",
      "2    P_00009        MLO  MALIGNANT\n",
      "3    P_00018        MLO     BENIGN\n",
      "4    P_00021        MLO     BENIGN\n"
     ]
    }
   ],
   "source": [
    "# Fixed function to get properly paired CC and MLO samples\n",
    "def get_paired_samples(df):\n",
    "    \"\"\"\n",
    "    Filter for patients with exactly one CC and one MLO view.\n",
    "    Returns two aligned dataframes: cc_views and mlo_views\n",
    "    \"\"\"\n",
    "    # Group by patient_id and ensure both CC and MLO views exist\n",
    "    grouped = df.groupby('patient_id').filter(lambda x: set(x['image_view']) == {'CC', 'MLO'})\n",
    "    \n",
    "    # For each patient, select one CC and one MLO view (first occurrence of each)\n",
    "    cc_views = grouped[grouped['image_view'] == 'CC'].groupby('patient_id').first().reset_index()\n",
    "    mlo_views = grouped[grouped['image_view'] == 'MLO'].groupby('patient_id').first().reset_index()\n",
    "    \n",
    "    # Ensure only patients present in both CC and MLO are kept\n",
    "    common_patients = np.intersect1d(cc_views['patient_id'], mlo_views['patient_id'])\n",
    "    cc_views = cc_views[cc_views['patient_id'].isin(common_patients)].sort_values('patient_id').reset_index(drop=True)\n",
    "    mlo_views = mlo_views[mlo_views['patient_id'].isin(common_patients)].sort_values('patient_id').reset_index(drop=True)\n",
    "    \n",
    "    return cc_views, mlo_views\n",
    "\n",
    "# Apply the corrected function\n",
    "mass_train_cc, mass_train_mlo = get_paired_samples(mass_train)\n",
    "mass_test_cc, mass_test_mlo = get_paired_samples(mass_test)\n",
    "\n",
    "# Now verify alignment (this should work without errors)\n",
    "print(f\"Train CC samples: {len(mass_train_cc)}\")\n",
    "print(f\"Train MLO samples: {len(mass_train_mlo)}\")\n",
    "print(f\"Test CC samples: {len(mass_test_cc)}\")\n",
    "print(f\"Test MLO samples: {len(mass_test_mlo)}\")\n",
    "\n",
    "# Verify alignment\n",
    "assert len(mass_train_cc) == len(mass_train_mlo), f\"Train lengths mismatched: CC={len(mass_train_cc)}, MLO={len(mass_train_mlo)}\"\n",
    "assert len(mass_test_cc) == len(mass_test_mlo), f\"Test lengths mismatched: CC={len(mass_test_cc)}, MLO={len(mass_test_mlo)}\"\n",
    "\n",
    "assert (mass_train_cc['patient_id'].values == mass_train_mlo['patient_id'].values).all(), \"Train patient IDs misaligned\"\n",
    "assert (mass_test_cc['patient_id'].values == mass_test_mlo['patient_id'].values).all(), \"Test patient IDs misaligned\"\n",
    "\n",
    "print(\"✅ All alignment checks passed!\")\n",
    "\n",
    "# Display some statistics\n",
    "print(f\"\\nTraining patients with paired CC/MLO views: {len(mass_train_cc)}\")\n",
    "print(f\"Testing patients with paired CC/MLO views: {len(mass_test_cc)}\")\n",
    "\n",
    "# Show sample of aligned data\n",
    "print(\"\\n--- Sample of aligned training data ---\")\n",
    "print(\"CC views:\")\n",
    "print(mass_train_cc[['patient_id', 'image_view', 'pathology']].head())\n",
    "print(\"\\nMLO views:\")\n",
    "print(mass_train_mlo[['patient_id', 'image_view', 'pathology']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-10T13:11:21.483855Z",
     "iopub.status.busy": "2025-06-10T13:11:21.482961Z",
     "iopub.status.idle": "2025-06-10T13:11:21.491998Z",
     "shell.execute_reply": "2025-06-10T13:11:21.490793Z",
     "shell.execute_reply.started": "2025-06-10T13:11:21.483824Z"
    }
   },
   "outputs": [],
   "source": [
    "# Map pathology to binary labels (MALIGNANT = 1, BENIGN/BENIGN_WITHOUT_CALLBACK = 0)\n",
    "mass_train_cc['label'] = mass_train_cc['pathology'].map(lambda x: '1' if x == 'MALIGNANT' else '0')\n",
    "mass_train_mlo['label'] = mass_train_mlo['pathology'].map(lambda x: '1' if x == 'MALIGNANT' else '0')\n",
    "mass_test_cc['label'] = mass_test_cc['pathology'].map(lambda x: '1' if x == 'MALIGNANT' else '0')\n",
    "mass_test_mlo['label'] = mass_test_mlo['pathology'].map(lambda x: '1' if x == 'MALIGNANT' else '0')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-10T13:41:27.406650Z",
     "iopub.status.busy": "2025-06-10T13:41:27.406247Z",
     "iopub.status.idle": "2025-06-10T13:41:27.421990Z",
     "shell.execute_reply": "2025-06-10T13:41:27.420934Z",
     "shell.execute_reply.started": "2025-06-10T13:41:27.406606Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mass_train_cc after mapping:\n",
      "   pathology label\n",
      "0  MALIGNANT     1\n",
      "1     BENIGN     0\n",
      "2  MALIGNANT     1\n",
      "3     BENIGN     0\n",
      "4     BENIGN     0\n",
      "\n",
      "mass_train_mlo after mapping:\n",
      "   pathology label\n",
      "0  MALIGNANT     1\n",
      "1     BENIGN     0\n",
      "2  MALIGNANT     1\n",
      "3     BENIGN     0\n",
      "4     BENIGN     0\n",
      "mass_train_cc after mapping:\n",
      "   pathology label\n",
      "0  MALIGNANT     1\n",
      "1  MALIGNANT     1\n",
      "2     BENIGN     0\n",
      "3  MALIGNANT     1\n",
      "4  MALIGNANT     1\n",
      "\n",
      "mass_train_mlo after mapping:\n",
      "   pathology label\n",
      "0  MALIGNANT     1\n",
      "1  MALIGNANT     1\n",
      "2     BENIGN     0\n",
      "3  MALIGNANT     1\n",
      "4  MALIGNANT     1\n"
     ]
    }
   ],
   "source": [
    "        print(\"mass_train_cc after mapping:\")\n",
    "        print(mass_train_cc[['pathology', 'label']].head())  # Show pathology and label columns\n",
    "\n",
    "        print(\"\\nmass_train_mlo after mapping:\")\n",
    "        print(mass_train_mlo[['pathology', 'label']].head())\n",
    "\n",
    "        # ... repeat for test sets\n",
    "        print(\"mass_train_cc after mapping:\")\n",
    "        print(mass_test_cc[['pathology', 'label']].head())  # Show pathology and label columns\n",
    "\n",
    "        print(\"\\nmass_train_mlo after mapping:\")\n",
    "        print(mass_test_mlo[['pathology', 'label']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-10T13:47:14.468630Z",
     "iopub.status.busy": "2025-06-10T13:47:14.468241Z",
     "iopub.status.idle": "2025-06-10T13:47:14.479272Z",
     "shell.execute_reply": "2025-06-10T13:47:14.478330Z",
     "shell.execute_reply.started": "2025-06-10T13:47:14.468604Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CC Training label counts:\n",
      " label\n",
      "0    246\n",
      "1    244\n",
      "Name: count, dtype: int64\n",
      "CC Testing label counts:\n",
      " label\n",
      "0    87\n",
      "1    59\n",
      "Name: count, dtype: int64\n",
      "MLO Training label counts:\n",
      " label\n",
      "0    247\n",
      "1    243\n",
      "Name: count, dtype: int64\n",
      "MLO Testing label counts:\n",
      " label\n",
      "0    87\n",
      "1    59\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Confirm distribution\n",
    "print(\"CC Training label counts:\\n\", mass_train_cc['label'].value_counts())\n",
    "print(\"CC Testing label counts:\\n\", mass_test_cc['label'].value_counts())\n",
    "\n",
    "\n",
    "# Confirm distribution\n",
    "print(\"MLO Training label counts:\\n\", mass_train_mlo['label'].value_counts())\n",
    "print(\"MLO Testing label counts:\\n\", mass_test_mlo['label'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-10T15:04:42.509007Z",
     "iopub.status.busy": "2025-06-10T15:04:42.508587Z",
     "iopub.status.idle": "2025-06-10T15:04:45.685566Z",
     "shell.execute_reply": "2025-06-10T15:04:45.684600Z",
     "shell.execute_reply.started": "2025-06-10T15:04:42.508976Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 490 validated image filenames belonging to 2 classes.\n",
      "Found 146 validated image filenames belonging to 2 classes.\n",
      "Found 490 validated image filenames belonging to 2 classes.\n",
      "Found 146 validated image filenames belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# use only cropped_image_path (just misses out on important anatomical details)\n",
    "\n",
    "\n",
    "\n",
    "# Data augmentation for training, basic rescale for testing\n",
    "train_datagen = ImageDataGenerator(rescale=1./255, horizontal_flip=True, rotation_range=10)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Constants\n",
    "IMG_SIZE = (224, 224)\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Train generator using cropped image only\n",
    "train_generator_cc = train_datagen.flow_from_dataframe(\n",
    "    dataframe=mass_train_cc,\n",
    "    x_col='cropped_image_file_path',\n",
    "    y_col='label',\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary',\n",
    "    shuffle = True\n",
    ")\n",
    "\n",
    "# Test generator\n",
    "test_generator_cc = test_datagen.flow_from_dataframe(\n",
    "    dataframe=mass_test_cc,\n",
    "    x_col='cropped_image_file_path',\n",
    "    y_col='label',\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# use only cropped_image_path (just misses out on important anatomical details)\n",
    "\n",
    "# use only cropped_image_path (just misses out on important anatomical details)\n",
    "\n",
    "\n",
    "\n",
    "# Data augmentation for training, basic rescale for testing\n",
    "train_datagen = ImageDataGenerator(rescale=1./255, horizontal_flip=True, rotation_range=10)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Constants\n",
    "IMG_SIZE = (224, 224)\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Train generator using cropped image only\n",
    "train_generator_mlo = train_datagen.flow_from_dataframe(\n",
    "    dataframe=mass_train_mlo,\n",
    "    x_col='cropped_image_file_path',\n",
    "    y_col='label',\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary',\n",
    "    shuffle = True\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# Test generator\n",
    "test_generator_mlo = test_datagen.flow_from_dataframe(\n",
    "    dataframe=mass_test_mlo,\n",
    "    x_col='cropped_image_file_path',\n",
    "    y_col='label',\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-10T15:04:51.029247Z",
     "iopub.status.busy": "2025-06-10T15:04:51.028793Z",
     "iopub.status.idle": "2025-06-10T15:04:52.698312Z",
     "shell.execute_reply": "2025-06-10T15:04:52.697346Z",
     "shell.execute_reply.started": "2025-06-10T15:04:51.029212Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-10 15:04:51.051851: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    }
   ],
   "source": [
    "# feature vectors model \n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def build_EffB0_feature_extractor_cc(img_size=(224, 224, 3), unfreeze_ratio=0.5):\n",
    "    base_model = EfficientNetB0(input_shape=img_size, include_top=False, weights='imagenet')\n",
    "    \n",
    "    # Freeze base model initially\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "    \n",
    "    # Unfreeze last unfreeze_ratio% of layers (same as MLO)\n",
    "    unfreeze_index = int(len(base_model.layers) * (1 - unfreeze_ratio))\n",
    "    for layer in base_model.layers[unfreeze_index:]:\n",
    "        layer.trainable = True\n",
    "    \n",
    "    x_cc = GlobalAveragePooling2D()(base_model.output)\n",
    "    x_cc = Dense(512, activation='relu')(x_cc)\n",
    "    x_cc =BatchNormalization()(x_cc)\n",
    "    output = Dropout(0.4)(x_cc)\n",
    "\n",
    "\n",
    "    # binary classification to check model performance ()\n",
    "    # x_cc = Dropout(0.4)(x_cc)\n",
    "    # output = Dense(1, activation='sigmoid')(x_cc)  #Binary classification\n",
    "    \n",
    "    # return Model(inputs=base_model.input, outputs=output)\n",
    "    return Model(inputs=base_model.input, outputs=output, name='cc_feature_extractor')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Build model\n",
    "EffB0_model_cc = build_EffB0_feature_extractor_cc()\n",
    "# EffB0_model_cc.summary()\n",
    "\n",
    "                              \n",
    "                             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-10T15:04:59.241181Z",
     "iopub.status.busy": "2025-06-10T15:04:59.240792Z",
     "iopub.status.idle": "2025-06-10T15:05:44.720685Z",
     "shell.execute_reply": "2025-06-10T15:05:44.719543Z",
     "shell.execute_reply.started": "2025-06-10T15:04:59.241158Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 2s/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1s/step\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Just get the features\n",
    "cc_feature_vectors_train = EffB0_model_cc.predict(train_generator_cc, verbose=1)\n",
    "cc_feature_vectors_test = EffB0_model_cc.predict(test_generator_cc, verbose=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-10T15:05:44.722926Z",
     "iopub.status.busy": "2025-06-10T15:05:44.722660Z",
     "iopub.status.idle": "2025-06-10T15:05:44.731587Z",
     "shell.execute_reply": "2025-06-10T15:05:44.730439Z",
     "shell.execute_reply.started": "2025-06-10T15:05:44.722907Z"
    }
   },
   "outputs": [],
   "source": [
    "np.save(\"cc_feature_vectors_train.npy\", cc_feature_vectors_train)\n",
    "np.save(\"cc_feature_vectors_test.npy\", cc_feature_vectors_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-10T15:05:46.286732Z",
     "iopub.status.busy": "2025-06-10T15:05:46.286391Z",
     "iopub.status.idle": "2025-06-10T15:05:47.560767Z",
     "shell.execute_reply": "2025-06-10T15:05:47.559641Z",
     "shell.execute_reply.started": "2025-06-10T15:05:46.286709Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_EffB0_feature_extractor_mlo(img_size=(224, 224, 3), unfreeze_ratio=0.5):\n",
    "    from tensorflow.keras.applications import EfficientNetB0\n",
    "    from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\n",
    "    from tensorflow.keras.models import Model\n",
    "\n",
    "    base_model = EfficientNetB0(input_shape=img_size, include_top=False, weights='imagenet')\n",
    "    \n",
    "    # Freeze base model initially\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # Unfreeze last unfreeze_ratio% of layers\n",
    "    unfreeze_index = int(len(base_model.layers) * (1 - unfreeze_ratio))\n",
    "    for layer in base_model.layers[unfreeze_index:]:\n",
    "        layer.trainable = True\n",
    "\n",
    "    # Classification head\n",
    "    x_mlo = GlobalAveragePooling2D()(base_model.output)\n",
    "    x_mlo = Dense(512, activation='relu')(x_mlo)\n",
    "    x_mlo =BatchNormalization()(x_mlo)  # Normalizes 512 features\n",
    "    output = Dropout(0.4)(x_mlo)\n",
    "    \n",
    "    \n",
    "    # binary classification to check model performance ()\n",
    "    # x_mlo = Dropout(0.4)(x_mlo)\n",
    "    # output = Dense(1, activation='sigmoid')(x_mlo)  #Binary classification\n",
    "\n",
    "    # return Model(inputs=base_model.input, outputs=output)\n",
    "    \n",
    "    return Model(inputs=base_model.input, outputs=output, name='mlo_feature_extractor')\n",
    "\n",
    "\n",
    "# Build model\n",
    "EffB0_model_mlo = build_EffB0_feature_extractor_mlo()\n",
    "# EffB0_model_mlo.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-10T15:06:40.543456Z",
     "iopub.status.busy": "2025-06-10T15:06:40.542719Z",
     "iopub.status.idle": "2025-06-10T15:07:14.534193Z",
     "shell.execute_reply": "2025-06-10T15:07:14.533266Z",
     "shell.execute_reply.started": "2025-06-10T15:06:40.543422Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 2s/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1s/step\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Just get the features\n",
    "mlo_feature_vectors_train = EffB0_model_mlo.predict(train_generator_mlo, verbose=1)\n",
    "mlo_feature_vectors_test = EffB0_model_mlo.predict(test_generator_mlo, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-10T15:07:14.536160Z",
     "iopub.status.busy": "2025-06-10T15:07:14.535784Z",
     "iopub.status.idle": "2025-06-10T15:07:14.543398Z",
     "shell.execute_reply": "2025-06-10T15:07:14.542315Z",
     "shell.execute_reply.started": "2025-06-10T15:07:14.536134Z"
    }
   },
   "outputs": [],
   "source": [
    "np.save(\"mlo_feature_vectors_train.npy\", mlo_feature_vectors_train)\n",
    "np.save(\"mlo_feature_vectors_test.npy\", mlo_feature_vectors_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-10T15:07:14.565478Z",
     "iopub.status.busy": "2025-06-10T15:07:14.565220Z",
     "iopub.status.idle": "2025-06-10T15:07:14.585177Z",
     "shell.execute_reply": "2025-06-10T15:07:14.584107Z",
     "shell.execute_reply.started": "2025-06-10T15:07:14.565453Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cc_feature_vectors_train shape: (490, 512)\n",
      "mlo_feature_vectors_train shape: (490, 512)\n",
      "cc_feature_vectors_test shape: (146, 512)\n",
      "mlo_feature_vectors_test shape: (146, 512)\n"
     ]
    }
   ],
   "source": [
    "print(f\"cc_feature_vectors_train shape: {cc_feature_vectors_train.shape}\")\n",
    "print(f\"mlo_feature_vectors_train shape: {mlo_feature_vectors_train.shape}\")\n",
    "print(f\"cc_feature_vectors_test shape: {cc_feature_vectors_test.shape}\")\n",
    "print(f\"mlo_feature_vectors_test shape: {mlo_feature_vectors_test.shape}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-10T15:21:20.344215Z",
     "iopub.status.busy": "2025-06-10T15:21:20.343740Z",
     "iopub.status.idle": "2025-06-10T15:21:20.355404Z",
     "shell.execute_reply": "2025-06-10T15:21:20.354345Z",
     "shell.execute_reply.started": "2025-06-10T15:21:20.344189Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CC Train Features Shape: (490, 512)\n",
      "MLO Train Features Shape: (490, 512)\n",
      "CC Test Features Shape: (146, 512)\n",
      "MLO Test Features Shape: (146, 512)\n",
      "Train Labels Shape: (490,)\n",
      "Test Labels Shape: (146,)\n"
     ]
    }
   ],
   "source": [
    "# Load the saved feature vectors\n",
    "cc_feature_vectors_train = np.load(\"cc_feature_vectors_train.npy\")\n",
    "mlo_feature_vectors_train = np.load(\"mlo_feature_vectors_train.npy\")\n",
    "cc_feature_vectors_test = np.load(\"cc_feature_vectors_test.npy\")\n",
    "mlo_feature_vectors_test = np.load(\"mlo_feature_vectors_test.npy\")\n",
    "\n",
    "# Get labels from the dataframes\n",
    "train_labels = mass_train_cc['label'].values.astype(np.float32)  # Assuming labels are aligned\n",
    "test_labels = mass_test_cc['label'].values.astype(np.float32)\n",
    "\n",
    "# Verify shapes\n",
    "print(f\"CC Train Features Shape: {cc_feature_vectors_train.shape}\")\n",
    "print(f\"MLO Train Features Shape: {mlo_feature_vectors_train.shape}\")\n",
    "print(f\"CC Test Features Shape: {cc_feature_vectors_test.shape}\")\n",
    "print(f\"MLO Test Features Shape: {mlo_feature_vectors_test.shape}\")\n",
    "print(f\"Train Labels Shape: {train_labels.shape}\")\n",
    "print(f\"Test Labels Shape: {test_labels.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-10T15:22:00.018035Z",
     "iopub.status.busy": "2025-06-10T15:22:00.017677Z",
     "iopub.status.idle": "2025-06-10T15:22:00.025436Z",
     "shell.execute_reply": "2025-06-10T15:22:00.024055Z",
     "shell.execute_reply.started": "2025-06-10T15:22:00.018012Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define the dual-view classifier\n",
    "def build_dual_view_classifier():\n",
    "    # Input layers for CC and MLO feature vectors\n",
    "    cc_input = Input(shape=(512,), name='cc_input')\n",
    "    mlo_input = Input(shape=(512,), name='mlo_input')\n",
    "    \n",
    "    # Concatenate the CC and MLO feature vectors\n",
    "    combined = Concatenate()([cc_input, mlo_input])\n",
    "    \n",
    "    # Add dense layers for classification\n",
    "    x = Dense(256, activation='relu')(combined)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.4)(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.4)(x)\n",
    "    output = Dense(1, activation='sigmoid')(x)  # Binary classification\n",
    "    \n",
    "    # Create the model\n",
    "    model = Model(inputs=[cc_input, mlo_input], outputs=output, name='dual_view_classifier')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-10T15:22:21.397090Z",
     "iopub.status.busy": "2025-06-10T15:22:21.396676Z",
     "iopub.status.idle": "2025-06-10T15:22:21.494878Z",
     "shell.execute_reply": "2025-06-10T15:22:21.493757Z",
     "shell.execute_reply.started": "2025-06-10T15:22:21.397060Z"
    }
   },
   "outputs": [],
   "source": [
    "# Build the model\n",
    "dual_view_model = build_dual_view_classifier()\n",
    "\n",
    "# Compile the model\n",
    "dual_view_model.compile(optimizer='adam', \n",
    "                       loss='binary_crossentropy', \n",
    "                       metrics=['accuracy', tf.keras.metrics.AUC(name='auc')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-10T15:22:44.933180Z",
     "iopub.status.busy": "2025-06-10T15:22:44.932787Z",
     "iopub.status.idle": "2025-06-10T15:22:44.961037Z",
     "shell.execute_reply": "2025-06-10T15:22:44.959849Z",
     "shell.execute_reply.started": "2025-06-10T15:22:44.933155Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"dual_view_classifier\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"dual_view_classifier\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ cc_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ mlo_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ concatenate (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ cc_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],        │\n",
       "│                           │                        │                │ mlo_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">262,400</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ batch_normalization_2     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ dense_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_2… │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │ dropout_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ batch_normalization_3     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │            <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ dense_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_3… │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │ dropout_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ cc_input (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ mlo_input (\u001b[38;5;33mInputLayer\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ concatenate (\u001b[38;5;33mConcatenate\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ cc_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],        │\n",
       "│                           │                        │                │ mlo_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │        \u001b[38;5;34m262,400\u001b[0m │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ batch_normalization_2     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │          \u001b[38;5;34m1,024\u001b[0m │ dense_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_2… │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │         \u001b[38;5;34m32,896\u001b[0m │ dropout_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ batch_normalization_3     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │            \u001b[38;5;34m512\u001b[0m │ dense_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_3… │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m129\u001b[0m │ dropout_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">296,961</span> (1.13 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m296,961\u001b[0m (1.13 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">296,193</span> (1.13 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m296,193\u001b[0m (1.13 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">768</span> (3.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m768\u001b[0m (3.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dual_view_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-10T15:23:05.554287Z",
     "iopub.status.busy": "2025-06-10T15:23:05.553867Z",
     "iopub.status.idle": "2025-06-10T15:23:13.431084Z",
     "shell.execute_reply": "2025-06-10T15:23:13.430278Z",
     "shell.execute_reply.started": "2025-06-10T15:23:05.554261Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 52ms/step - accuracy: 0.5213 - auc: 0.5052 - loss: 0.7495 - val_accuracy: 0.5959 - val_auc: 0.5000 - val_loss: 0.6888\n",
      "Epoch 2/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5321 - auc: 0.5329 - loss: 0.7271 - val_accuracy: 0.5959 - val_auc: 0.5000 - val_loss: 0.6843\n",
      "Epoch 3/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5663 - auc: 0.5847 - loss: 0.6917 - val_accuracy: 0.5959 - val_auc: 0.5000 - val_loss: 0.6832\n",
      "Epoch 4/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5655 - auc: 0.6076 - loss: 0.6799 - val_accuracy: 0.5959 - val_auc: 0.5000 - val_loss: 0.6799\n",
      "Epoch 5/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5734 - auc: 0.5846 - loss: 0.7148 - val_accuracy: 0.5959 - val_auc: 0.5000 - val_loss: 0.6859\n",
      "Epoch 6/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6001 - auc: 0.6386 - loss: 0.6644 - val_accuracy: 0.5959 - val_auc: 0.5000 - val_loss: 0.6782\n",
      "Epoch 7/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5921 - auc: 0.6186 - loss: 0.6793 - val_accuracy: 0.5959 - val_auc: 0.4713 - val_loss: 0.6748\n",
      "Epoch 8/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5652 - auc: 0.5978 - loss: 0.6908 - val_accuracy: 0.5959 - val_auc: 0.4780 - val_loss: 0.6747\n",
      "Epoch 9/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5554 - auc: 0.6042 - loss: 0.6922 - val_accuracy: 0.5959 - val_auc: 0.4713 - val_loss: 0.6794\n",
      "Epoch 10/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5543 - auc: 0.6026 - loss: 0.6905 - val_accuracy: 0.5959 - val_auc: 0.5033 - val_loss: 0.6821\n",
      "Epoch 11/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5987 - auc: 0.6488 - loss: 0.6555 - val_accuracy: 0.5959 - val_auc: 0.5206 - val_loss: 0.6778\n",
      "Epoch 12/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5593 - auc: 0.6071 - loss: 0.6882 - val_accuracy: 0.5959 - val_auc: 0.4885 - val_loss: 0.6768\n",
      "Epoch 13/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5933 - auc: 0.6369 - loss: 0.6647 - val_accuracy: 0.5959 - val_auc: 0.4254 - val_loss: 0.6789\n"
     ]
    }
   ],
   "source": [
    "# Define early stopping to prevent overfitting\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "# Train the model\n",
    "history = dual_view_model.fit(\n",
    "    [cc_feature_vectors_train, mlo_feature_vectors_train],  # Inputs: CC and MLO features\n",
    "    train_labels,  # Labels\n",
    "    validation_data=([cc_feature_vectors_test, mlo_feature_vectors_test], test_labels),\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    callbacks=[early_stopping],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-10T15:25:36.105575Z",
     "iopub.status.busy": "2025-06-10T15:25:36.105237Z",
     "iopub.status.idle": "2025-06-10T15:25:36.111250Z",
     "shell.execute_reply": "2025-06-10T15:25:36.110208Z",
     "shell.execute_reply.started": "2025-06-10T15:25:36.105552Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    }
   ],
   "source": [
    "print(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply filtering\n",
    "mass_train_paired = get_paired_samples(mass_train)\n",
    "mass_test_paired = get_paired_samples(mass_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mass_train_paired.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into CC and MLO views\n",
    "mass_train_cc = mass_train_paired[mass_train_paired['image_view'] == 'CC'].copy()\n",
    "mass_train_mlo = mass_train_paired[mass_train_paired['image_view'] == 'MLO'].copy()\n",
    "mass_test_cc = mass_test_paired[mass_test_paired['image_view'] == 'CC'].copy()\n",
    "mass_test_mlo = mass_test_paired[mass_test_paired['image_view'] == 'MLO'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by patient_id to ensure alignment\n",
    "mass_train_cc = mass_train_cc.sort_values('patient_id').reset_index(drop=True)\n",
    "mass_train_mlo = mass_train_mlo.sort_values('patient_id').reset_index(drop=True)\n",
    "mass_test_cc = mass_test_cc.sort_values('patient_id').reset_index(drop=True)\n",
    "mass_test_mlo = mass_test_mlo.sort_values('patient_id').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify alignment\n",
    "assert (mass_train_cc['patient_id'] == mass_train_mlo['patient_id']).all(), \"Train patient IDs misaligned\"\n",
    "assert (mass_test_cc['patient_id'] == mass_test_mlo['patient_id']).all(), \"Test patient IDs misaligned\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check sample counts\n",
    "print(\"Train CC samples:\", len(mass_train_cc))\n",
    "print(\"Train MLO samples:\", len(mass_train_mlo))\n",
    "print(\"Test CC samples:\", len(mass_test_cc))\n",
    "print(\"Test MLO samples:\", len(mass_test_mlo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CC Pathway"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter to obtain only the CC views \n",
    "\n",
    "mass_train_cc = mass_train_paired[mass_train['image_view'] == 'CC'].copy()\n",
    "mass_test_cc = mass_test_paired[mass_test['image_view'] == 'CC'].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mass_train_cc.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mass_test_cc.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mass_train_cc.pathology.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mass_test_cc.pathology.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_smaples(mass_train_cc['image_file_path'].values, row=15, col=15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_smaples(mass_test_cc['image_file_path'].values, row=15, col=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # given the outputs above the classes are relatively balanced ([296 vs 311 in training] and [67 vs 110 in testing]) \n",
    "# # no need of class balancing as of now\n",
    "\n",
    "# Label Mapping and Verification\n",
    "\n",
    "# Map pathology to binary labels (malignant = 1, benign and others ( benign_without_callback) = 0)\n",
    "mass_train_cc['label'] = mass_train_cc['pathology'].map(lambda x: '1' if x == 'MALIGNANT' else '0')\n",
    "mass_test_cc['label'] = mass_test_cc['pathology'].map(lambda x: '1' if x == 'MALIGNANT' else '0')\n",
    "\n",
    "# Confirm distribution\n",
    "print(\"Training label counts:\\n\", mass_train_cc['label'].value_counts())\n",
    "print(\"Testing label counts:\\n\", mass_test_cc['label'].value_counts())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use only cropped_image_path (just misses out on important anatomical details)\n",
    "\n",
    "\n",
    "\n",
    "# Data augmentation for training, basic rescale for testing\n",
    "train_datagen = ImageDataGenerator(rescale=1./255, horizontal_flip=True, rotation_range=10)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Constants\n",
    "IMG_SIZE = (224, 224)\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Train generator using cropped image only\n",
    "train_generator_cc = train_datagen.flow_from_dataframe(\n",
    "    dataframe=mass_train_cc,\n",
    "    x_col='cropped_image_file_path',\n",
    "    y_col='label',\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary',\n",
    "    shuffle = True\n",
    ")\n",
    "\n",
    "# Test generator\n",
    "test_generator_cc = test_datagen.flow_from_dataframe(\n",
    "    dataframe=mass_test_cc,\n",
    "    x_col='cropped_image_file_path',\n",
    "    y_col='label',\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary',\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # for binary classification \n",
    "\n",
    "\n",
    "# import tensorflow as tf\n",
    "# from tensorflow.keras.applications import EfficientNetB0\n",
    "# from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D\n",
    "\n",
    "# # Step 1 - Load EfficientNetB0 as the base model\n",
    "# base_model = EfficientNetB0(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# # Step 2 - Freeze the base model layers\n",
    "# base_model.trainable = False  # Prevents pretrained weights from being updated\n",
    "\n",
    "# # Step 3 - Build the classification model\n",
    "# model = Sequential([\n",
    "#     base_model,\n",
    "#     GlobalAveragePooling2D(),  # Replaces Flatten for better feature extraction\n",
    "#     Dense(64, activation='relu'),\n",
    "#     Dropout(0.5),\n",
    "#     Dense(1, activation='sigmoid')  # Binary classification\n",
    "# ])\n",
    "\n",
    "# # Step 4 - Compile the model\n",
    "# model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# # Step 5 - Summary\n",
    "# model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # for binary classification \n",
    "\n",
    "\n",
    "# import tensorflow as tf\n",
    "# from tensorflow.keras.applications import EfficientNetB0\n",
    "# from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D\n",
    "\n",
    "# # Step 1 - Load EfficientNetB0 as the base model\n",
    "# base_model = EfficientNetB0(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# # Step 2 - Freeze the base model layers\n",
    "# base_model.trainable = False  # Prevents pretrained weights from being updated\n",
    "\n",
    "# # Step 3 - Build the classification model\n",
    "# model = Sequential([\n",
    "#     base_model,\n",
    "#     GlobalAveragePooling2D(),  # Replaces Flatten for better feature extraction\n",
    "#     Dense(64, activation='relu'),\n",
    "#     Dropout(0.5),\n",
    "#     Dense(1, activation='sigmoid')  # Binary classification\n",
    "# ])\n",
    "\n",
    "# # Step 4 - Compile the model\n",
    "# model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# # Step 5 - Summary\n",
    "# model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature vectors model \n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def build_EffB0_feature_extractor_cc(img_size=(224, 224, 3), unfreeze_ratio=0.5):\n",
    "    base_model = EfficientNetB0(input_shape=img_size, include_top=False, weights='imagenet')\n",
    "    \n",
    "    # Freeze base model initially\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "    \n",
    "    # Unfreeze last unfreeze_ratio% of layers (same as MLO)\n",
    "    unfreeze_index = int(len(base_model.layers) * (1 - unfreeze_ratio))\n",
    "    for layer in base_model.layers[unfreeze_index:]:\n",
    "        layer.trainable = True\n",
    "    \n",
    "    x_cc = GlobalAveragePooling2D()(base_model.output)\n",
    "    x_cc = Dense(512, activation='relu')(x_cc)\n",
    "    x_cc =BatchNormalization()(x_cc)\n",
    "    output = Dropout(0.4)(x_cc)\n",
    "\n",
    "\n",
    "    # binary classification to check model performance ()\n",
    "    # x_cc = Dropout(0.4)(x_cc)\n",
    "    # output = Dense(1, activation='sigmoid')(x_cc)  #Binary classification\n",
    "    \n",
    "    # return Model(inputs=base_model.input, outputs=output)\n",
    "    return Model(inputs=base_model.input, outputs=output, name='cc_feature_extractor')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Build model\n",
    "EffB0_model_cc = build_EffB0_feature_extractor_cc()\n",
    "EffB0_model_cc.summary()\n",
    "\n",
    "                              \n",
    "                             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# from tensorflow.keras.applications import EfficientNetB0\n",
    "# from tensorflow.keras.models import Model\n",
    "# from tensorflow.keras.layers import (\n",
    "#     GlobalAveragePooling2D, \n",
    "#     Dense, \n",
    "#     Dropout, \n",
    "#     BatchNormalization,\n",
    "#     LayerNormalization,\n",
    "#     Concatenate\n",
    "# )\n",
    "\n",
    "# def build_improved_feature_extractor(img_size=(224, 224, 3)):\n",
    "#     # Base model (EfficientNetB0, frozen)\n",
    "#     base_model = EfficientNetB0(\n",
    "#         input_shape=img_size, \n",
    "#         include_top=False, \n",
    "#         weights='imagenet',\n",
    "#         pooling=None  # Explicitly no pooling to allow multi-level feature fusion\n",
    "#     )\n",
    "#     base_model.trainable = False  # Freeze pretrained weights\n",
    "\n",
    "#     # Multi-level feature fusion (optional: concat GAP and GMP)\n",
    "#     gap = GlobalAveragePooling2D()(base_model.output)\n",
    "#     gmp = tf.keras.layers.GlobalMaxPooling2D()(base_model.output)\n",
    "#     fused_features = Concatenate()([gap, gmp])  # Combines avg and max pooled features\n",
    "\n",
    "#     # Non-linear projection head (improves feature separation)\n",
    "#     x = Dense(1024, activation='relu')(fused_features)\n",
    "#     x = BatchNormalization()(x)  # Stabilizes training\n",
    "#     x = Dropout(0.3)(x)\n",
    "    \n",
    "#     # L2-normalized output (critical for similarity tasks)\n",
    "#     output = tf.keras.layers.Lambda(\n",
    "#         lambda x: tf.math.l2_normalize(x, axis=1)\n",
    "#     )(x)\n",
    "\n",
    "#     return Model(inputs=base_model.input, outputs=output)\n",
    "\n",
    "# # Build and verify\n",
    "# model = build_improved_feature_extractor()\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # for binary classification \n",
    "# from tensorflow.keras.optimizers import Adam\n",
    "# from tensorflow.keras.metrics import Precision, Recall, AUC\n",
    "# import tensorflow_addons as tfa  # For F1 score\n",
    "\n",
    "# EffB0_model.compile(\n",
    "#     optimizer=Adam(learning_rate=1e-4),\n",
    "#     loss='binary_crossentropy',\n",
    "#     metrics=[\n",
    "#         'accuracy',\n",
    "#         Precision(name='precision'),\n",
    "#         Recall(name='recall'),\n",
    "#         AUC(name='auc'),\n",
    "#         tfa.metrics.F1Score(num_classes=1, average='micro', threshold=0.5, name='f1_score')\n",
    "#     ]\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.optimizers import Adam\n",
    "# from tensorflow.keras.metrics import Precision, Recall, AUC\n",
    "\n",
    "# EffB0_model_cc.compile(\n",
    "#     optimizer=Adam(learning_rate=1e-5),\n",
    "#     loss='binary_crossentropy',\n",
    "#     metrics=[\n",
    "#         'accuracy',\n",
    "#         Precision(name='precision'),\n",
    "#         Recall(name='recall'),\n",
    "#         AUC(name='auc'),\n",
    "        \n",
    "#     ]\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "# # Callbacks to stop training early if val_loss doesn't improve and to save best weights\n",
    "# early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "# checkpoint = ModelCheckpoint('best_effb0_model.h5', monitor='val_loss', save_best_only=True)\n",
    "\n",
    "# # Train the model\n",
    "# history_cc = EffB0_model_cc.fit(\n",
    "#     train_generator_cc,\n",
    "#     epochs=12,\n",
    "#     validation_data=test_generator_cc,\n",
    "#     callbacks=[early_stop, checkpoint]\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just get the features\n",
    "cc_feature_vectors_train = EffB0_model_cc.predict(train_generator_cc, verbose=1)\n",
    "cc_feature_vectors_test = EffB0_model_cc.predict(test_generator_cc, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"cc_feature_vectors_train.npy\", cc_feature_vectors_train)\n",
    "np.save(\"cc_feature_vectors_test.npy\", cc_feature_vectors_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Feature Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLO Pathway "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter to obtain only the MLO views \n",
    "\n",
    "mass_train_mlo = mass_train[mass_train['image_view'] == 'MLO'].copy()\n",
    "mass_test_mlo = mass_test[mass_test['image_view'] == 'MLO'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mass_train_mlo.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mass_test_mlo.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mass_train_mlo.pathology.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mass_test_mlo.pathology.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # given the outputs above the classes are relatively balanced ([341 vs 370 in training] and [100 vs 80 in testing]) \n",
    "# # no need of class balancing as of now\n",
    "\n",
    "# Label Mapping and Verification\n",
    "\n",
    "# Map pathology to binary labels (malignant = 1, benign and others ( benign_without_callback) = 0)\n",
    "mass_train_mlo['label'] = mass_train_mlo['pathology'].map(lambda x: '1' if x == 'MALIGNANT' else '0')\n",
    "mass_test_mlo['label'] = mass_test_mlo['pathology'].map(lambda x: '1' if x == 'MALIGNANT' else '0')\n",
    "\n",
    "# Confirm distribution\n",
    "print(\"Training label counts:\\n\", mass_train_mlo['label'].value_counts())\n",
    "print(\"Testing label counts:\\n\", mass_test_mlo['label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_smaples(mass_test_mlo['image_file_path'].values, row=15, col=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_smaples(mass_train_mlo['image_file_path'].values, row=15, col=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use only cropped_image_path (just misses out on important anatomical details)\n",
    "\n",
    "\n",
    "\n",
    "# Data augmentation for training, basic rescale for testing\n",
    "train_datagen = ImageDataGenerator(rescale=1./255, horizontal_flip=True, rotation_range=10)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Constants\n",
    "IMG_SIZE = (224, 224)\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Train generator using cropped image only\n",
    "train_generator_mlo = train_datagen.flow_from_dataframe(\n",
    "    dataframe=mass_train_mlo,\n",
    "    x_col='cropped_image_file_path',\n",
    "    y_col='label',\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary',\n",
    "    shuffle = True\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# Test generator\n",
    "test_generator_mlo = test_datagen.flow_from_dataframe(\n",
    "    dataframe=mass_test_mlo,\n",
    "    x_col='cropped_image_file_path',\n",
    "    y_col='label',\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary',\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_EffB0_feature_extractor_mlo(img_size=(224, 224, 3), unfreeze_ratio=0.5):\n",
    "    from tensorflow.keras.applications import EfficientNetB0\n",
    "    from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\n",
    "    from tensorflow.keras.models import Model\n",
    "\n",
    "    base_model = EfficientNetB0(input_shape=img_size, include_top=False, weights='imagenet')\n",
    "    \n",
    "    # Freeze base model initially\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # Unfreeze last unfreeze_ratio% of layers\n",
    "    unfreeze_index = int(len(base_model.layers) * (1 - unfreeze_ratio))\n",
    "    for layer in base_model.layers[unfreeze_index:]:\n",
    "        layer.trainable = True\n",
    "\n",
    "    # Classification head\n",
    "    x_mlo = GlobalAveragePooling2D()(base_model.output)\n",
    "    x_mlo = Dense(512, activation='relu')(x_mlo)\n",
    "    x_mlo =BatchNormalization()(x_mlo)  # Normalizes 512 features\n",
    "    output = Dropout(0.4)(x_mlo)\n",
    "    \n",
    "    \n",
    "    # binary classification to check model performance ()\n",
    "    # x_mlo = Dropout(0.4)(x_mlo)\n",
    "    # output = Dense(1, activation='sigmoid')(x_mlo)  #Binary classification\n",
    "\n",
    "    # return Model(inputs=base_model.input, outputs=output)\n",
    "    \n",
    "    return Model(inputs=base_model.input, outputs=output, name='mlo_feature_extractor')\n",
    "\n",
    "\n",
    "# Build model\n",
    "EffB0_model_mlo = build_EffB0_feature_extractor_mlo()\n",
    "EffB0_model_mlo.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.optimizers import Adam\n",
    "# from tensorflow.keras.metrics import Precision, Recall, AUC\n",
    "\n",
    "# EffB0_model_mlo.compile(\n",
    "#     optimizer=Adam(learning_rate=1e-5),\n",
    "#     loss='binary_crossentropy',\n",
    "#     metrics=[\n",
    "#         'accuracy',\n",
    "#         Precision(name='precision'),\n",
    "#         Recall(name='recall'),\n",
    "#         AUC(name='auc'),\n",
    "        \n",
    "#     ]\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "# # Callbacks to stop training early if val_loss doesn't improve and to save best weights\n",
    "# early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "# checkpoint = ModelCheckpoint('best_effb0_model.h5', monitor='val_loss', save_best_only=True)\n",
    "\n",
    "# # Train the model\n",
    "# history_mlo = EffB0_model_mlo.fit(\n",
    "#     train_generator_mlo,\n",
    "#     epochs=10,\n",
    "#     validation_data=test_generator_mlo,\n",
    "#     callbacks=[early_stop, checkpoint]\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just get the features\n",
    "mlo_feature_vectors_train = EffB0_model_mlo.predict(train_generator_mlo, verbose=1)\n",
    "mlo_feature_vectors_test = EffB0_model_mlo.predict(test_generator_mlo, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"mlo_feature_vectors_train.npy\", mlo_feature_vectors_train)\n",
    "np.save(\"mlo_feature_vectors_test.npy\", mlo_feature_vectors_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dual-View Model  Claude\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dual_view_model(img_size=(224, 224, 3), num_classes=1):  # Binary = 1 output\n",
    "    # Create feature extractors\n",
    "    cc_extractor = build_EffB0_feature_extractor_cc(img_size)\n",
    "    mlo_extractor = build_EffB0_feature_extractor_mlo(img_size)\n",
    "    \n",
    "    # Inputs for both views\n",
    "    cc_input = Input(shape=img_size, name='cc_input')\n",
    "    mlo_input = Input(shape=img_size, name='mlo_input')\n",
    "    \n",
    "    # Extract features from both pathways\n",
    "    cc_features = cc_extractor(cc_input)\n",
    "    mlo_features = mlo_extractor(mlo_input)\n",
    "    \n",
    "    # Fuse features\n",
    "    fused_features = Concatenate(name='feature_fusion')([cc_features, mlo_features])\n",
    "    \n",
    "    # Classification head\n",
    "    x = Dense(256, activation='relu')(fused_features)\n",
    "    x = Dropout(0.3)(x)\n",
    "    output = Dense(num_classes, activation='sigmoid', name='prediction')(x)  # Binary classification\n",
    "    \n",
    "    # Create the complete model\n",
    "    dual_model = Model(\n",
    "        inputs=[cc_input, mlo_input], \n",
    "        outputs=output,\n",
    "        name='dual_view_mammogram_classifier'\n",
    "    )\n",
    "    \n",
    "    return dual_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. DATA PREPARATION FOR DUAL-VIEW\n",
    "def create_paired_dataset(mass_train_cc, mass_train_mlo, mass_test_cc, mass_test_mlo):\n",
    "    \"\"\"\n",
    "    Create paired CC-MLO dataset for dual-view training\n",
    "    \"\"\"\n",
    "    # Merge CC and MLO data on patient_id and breast side\n",
    "    train_paired = pd.merge(\n",
    "        mass_train_cc[['patient_id', 'left_or_right_breast', 'cropped_image_file_path', 'label']],\n",
    "        mass_train_mlo[['patient_id', 'left_or_right_breast', 'cropped_image_file_path', 'label']],\n",
    "        on=['patient_id', 'left_or_right_breast'],\n",
    "        suffixes=('_cc', '_mlo')\n",
    "    )\n",
    "    \n",
    "    test_paired = pd.merge(\n",
    "        mass_test_cc[['patient_id', 'left_or_right_breast', 'cropped_image_file_path', 'label']],\n",
    "        mass_test_mlo[['patient_id', 'left_or_right_breast', 'cropped_image_file_path', 'label']],\n",
    "        on=['patient_id', 'left_or_right_breast'],\n",
    "        suffixes=('_cc', '_mlo')\n",
    "    )\n",
    "    \n",
    "    # Ensure labels match (they should for same patient/breast)\n",
    "    train_paired = train_paired[train_paired['label_cc'] == train_paired['label_mlo']]\n",
    "    test_paired = test_paired[test_paired['label_cc'] == test_paired['label_mlo']]\n",
    "    \n",
    "    print(f\"Paired training samples: {len(train_paired)}\")\n",
    "    print(f\"Paired testing samples: {len(test_paired)}\")\n",
    "    \n",
    "    return train_paired, test_paired\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DualViewDataGenerator(tf.keras.utils.Sequence):\n",
    "    def __init__(self, paired_df, batch_size=32, img_size=(224, 224), shuffle=True, augment=False):\n",
    "        super().__init__()  # This fixes the warning\n",
    "        self.paired_df = paired_df.reset_index(drop=True)\n",
    "        self.batch_size = batch_size\n",
    "        self.img_size = img_size\n",
    "        self.shuffle = shuffle\n",
    "        self.augment = augment\n",
    "        self.indices = np.arange(len(self.paired_df))\n",
    "        self.on_epoch_end()\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.paired_df) // self.batch_size\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        batch_indices = self.indices[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "        batch_df = self.paired_df.iloc[batch_indices]\n",
    "    \n",
    "        cc_images = []\n",
    "        mlo_images = []\n",
    "        labels = []\n",
    "\n",
    "        for _, row in batch_df.iterrows():\n",
    "            cc_img = tf.keras.preprocessing.image.load_img(row['cropped_image_file_path_cc'], target_size=self.img_size)\n",
    "            cc_img = tf.keras.preprocessing.image.img_to_array(cc_img) / 255.0\n",
    "        \n",
    "            mlo_img = tf.keras.preprocessing.image.load_img(row['cropped_image_file_path_mlo'], target_size=self.img_size)\n",
    "            mlo_img = tf.keras.preprocessing.image.img_to_array(mlo_img) / 255.0\n",
    "        \n",
    "            cc_images.append(cc_img)\n",
    "            mlo_images.append(mlo_img)\n",
    "            labels.append(float(row['label_cc']))\n",
    "            \n",
    "        return {'cc_input': np.array(cc_images),\n",
    "                'mlo_input': np.array(mlo_images)}, np.array(labels)\n",
    "\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_dual_view_model():\n",
    "    # Create paired datasets\n",
    "    train_paired, test_paired = create_paired_dataset(\n",
    "        mass_train_cc, mass_train_mlo, mass_test_cc, mass_test_mlo\n",
    "    )\n",
    "    \n",
    "    # Create data generators\n",
    "    train_generator = DualViewDataGenerator(\n",
    "        train_paired, \n",
    "        batch_size=32, \n",
    "        shuffle=True, \n",
    "        augment=True\n",
    "    )\n",
    "    \n",
    "    test_generator = DualViewDataGenerator(\n",
    "        test_paired, \n",
    "        batch_size=32, \n",
    "        shuffle=False, \n",
    "        augment=False\n",
    "    )\n",
    "    \n",
    "    # Build and compile model\n",
    "    dual_view_model = build_dual_view_model()\n",
    "    dual_view_model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy', 'precision', 'recall']\n",
    "    )\n",
    "    \n",
    "    # Training callbacks\n",
    "    callbacks = [\n",
    "        tf.keras.callbacks.EarlyStopping(\n",
    "            monitor='val_loss', \n",
    "            patience=10, \n",
    "            restore_best_weights=True\n",
    "        ),\n",
    "        tf.keras.callbacks.ReduceLROnPlateau(\n",
    "            monitor='val_loss', \n",
    "            factor=0.5, \n",
    "            patience=5\n",
    "        ),\n",
    "        tf.keras.callbacks.ModelCheckpoint(\n",
    "            'best_dual_view_model.h5',\n",
    "            monitor='val_accuracy',\n",
    "            save_best_only=True\n",
    "        )\n",
    "    ]\n",
    "    \n",
    "    # Train the model\n",
    "    history = dual_view_model.fit(\n",
    "        train_generator,\n",
    "        validation_data=test_generator,\n",
    "        epochs=50,\n",
    "        callbacks=callbacks\n",
    "    )\n",
    "    \n",
    "    return dual_view_model, history    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Don't compile individual extractors - just build the dual-view model\n",
    "print(\"Building dual-view model...\")\n",
    "dual_view_model = build_dual_view_model()\n",
    "dual_view_model.summary()\n",
    "\n",
    "# Train the complete model\n",
    "# model, history = train_dual_view_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model \n",
    "model, history = train_dual_view_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GROK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dual View CHATGPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.layers import Input, Concatenate, Dense, Dropout\n",
    "# from tensorflow.keras.models import Model\n",
    "\n",
    "# def build_dual_input_fusion_model(cc_model, mlo_model):\n",
    "#     # Freeze the feature extractor parts of both models\n",
    "#     cc_model.trainable = False\n",
    "#     mlo_model.trainable = False\n",
    "\n",
    "#     # Define separate inputs for CC and MLO images\n",
    "#     input_cc = Input(shape=(224, 224, 3), name='cc_input')\n",
    "#     input_mlo = Input(shape=(224, 224, 3), name='mlo_input')\n",
    "\n",
    "#     # Get the feature vectors from both pathways\n",
    "#     features_cc = cc_model(input_cc)   # shape: (None, 512)\n",
    "#     features_mlo = mlo_model(input_mlo)\n",
    "\n",
    "#     # Concatenate feature vectors\n",
    "#     concatenated = Concatenate()([features_cc, features_mlo])  # shape: (None, 1024)\n",
    "\n",
    "#     # Add classification head\n",
    "#     x = Dense(256, activation='relu')(concatenated)\n",
    "#     x = Dropout(0.5)(x)\n",
    "#     x = Dense(64, activation='relu')(x)\n",
    "#     x = Dropout(0.3)(x)\n",
    "#     output = Dense(1, activation='sigmoid')(x)  # Binary output\n",
    "\n",
    "#     # Create model\n",
    "#     fusion_model = Model(inputs=[input_cc, input_mlo], outputs=output, name='EfficientViewNet')\n",
    "\n",
    "#     return fusion_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Assume you have these models from your previous code\n",
    "# # EffB0_model_cc = build_EffB0_binary_cc()\n",
    "# # EffB0_model_mlo = build_EffB0_binary_mlo()\n",
    "\n",
    "# fusion_model = build_dual_input_fusion_model(EffB0_model_cc, EffB0_model_mlo)\n",
    "# fusion_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fusion_model.compile(\n",
    "#     optimizer='adam',\n",
    "#     loss='binary_crossentropy',\n",
    "#     metrics=[\n",
    "#         'accuracy',\n",
    "#         Precision(name='precision'),\n",
    "#         Recall(name='recall'),\n",
    "#         AUC(name='auc'),]\n",
    "        \n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# history_fusion = fusion_model.fit(\n",
    "\n",
    "\n",
    "    \n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"cc_feature_vectors_train shape: {cc_feature_vectors_train.shape}\")\n",
    "print(f\"mlo_feature_vectors_train shape: {mlo_feature_vectors_train.shape}\")\n",
    "print(f\"cc_feature_vectors_test shape: {cc_feature_vectors_test.shape}\")\n",
    "print(f\"mlo_feature_vectors_test shape: {mlo_feature_vectors_test.shape}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have a DataFrame with metadata\n",
    "common_ids = np.intersect1d(mass_train_cc['image_id'], mass_train_mlo['image_id'])\n",
    "cc_mask = mass_train_cc['image_id'].isin(common_ids)\n",
    "mlo_mask = mass_train_mlo['image_id'].isin(common_ids)\n",
    "\n",
    "# Filter feature vectors and labels\n",
    "cc_feature_vectors_train = cc_feature_vectors_train[cc_mask]\n",
    "mlo_feature_vectors_train = mlo_feature_vectors_train[mlo_mask]\n",
    "y_train = mass_train_cc[cc_mask]['label'].astype('int').values\n",
    "\n",
    "# Verify shapes after filtering\n",
    "print(\"Filtered cc_feature_vectors_train shape:\", cc_feature_vectors_train.shape)\n",
    "print(\"Filtered mlo_feature_vectors_train shape:\", mlo_feature_vectors_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concantenate the features\n",
    "X_train_combined = np.concatenate([cc_feature_vectors_train, mlo_feature_vectors_train], axis=1)\n",
    "X_test_combined = np.concatenate([cc_feature_vectors_test, mlo_feature_vectors_test], axis=1)\n",
    "\n",
    "# Get labels as integers (0 or 1)\n",
    "y_train = mass_train_cc['label'].astype('int').values\n",
    "y_test = mass_test_cc['label'].astype('int').values"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 1115384,
     "sourceId": 1873742,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31040,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
