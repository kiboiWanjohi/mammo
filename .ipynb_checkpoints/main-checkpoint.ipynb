{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding:utf-8\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from utils import progress_bar\n",
    "import os\n",
    "from torchvision import models\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import data_preprocess\n",
    "from correlation import corr\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "parser = argparse.ArgumentParser(description='PyTorch EfficientNet Training')\n",
    "parser.add_argument('--lr', default=5e-5, type=float, help='learning rate')\n",
    "args = parser.parse_args()\n",
    "\n",
    "def adjust_learning_rate(optimizer, decay_rate=.5):  \n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = param_group['lr'] * decay_rate\n",
    "    print(\"changing lr rate\")\n",
    "        \n",
    "print('==> Preparing data..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, imagesCC,labelsCC,imagesMLO,labelsMLO):\n",
    "        self.imagesCC = imagesCC\n",
    "        self.labelsCC = labelsCC\n",
    "        self.imagesMLO = imagesMLO\n",
    "        self.labelsMLO = labelsMLO\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        imgCC = torch.Tensor(self.imagesCC[index])\n",
    "        targetCC = self.labelsCC[index]\n",
    "        imgMLO = torch.Tensor(self.imagesMLO[index])\n",
    "        targetMLO = self.labelsMLO[index]\n",
    "        return imgCC,targetCC,imgMLO,targetMLO\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imagesCC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input image dimensions\n",
    "img_rows, img_cols = 256, 256\n",
    "img_channels = 1\n",
    "\n",
    "# the data, shuffled and split between train and test sets\n",
    "trXMLO, y_trainMLO, teXMLO, y_testMLO, trXCC, y_trainCC, teXCC, y_testCC = data_preprocess.loaddata()\n",
    "\n",
    "# Reshape labels\n",
    "trYMLO = y_trainMLO.reshape((y_trainMLO.shape[0],1))\n",
    "teYMLO = y_testMLO.reshape((y_testMLO.shape[0],1))\n",
    "trYCC = y_trainCC.reshape((y_trainCC.shape[0],1))\n",
    "teYCC = y_testCC.reshape((y_testCC.shape[0],1))\n",
    "\n",
    "ratio = trYMLO.sum()*1./trYMLO.shape[0]*1.\n",
    "\n",
    "train_len = len(trXMLO)\n",
    "test_len = len(teXMLO)\n",
    "print('tr ratio'+str(ratio))\n",
    "weights = np.array((ratio,1-ratio))\n",
    "weights = torch.Tensor(weights)\n",
    "weights = weights.cuda()\n",
    "\n",
    "# Reshape and convert to 3-channel\n",
    "def prepare_images(images):\n",
    "    images = images.reshape(-1, img_channels, img_rows, img_cols)\n",
    "    extended = np.zeros((images.shape[0], 3, img_rows, img_cols))\n",
    "    for i in range(images.shape[0]):\n",
    "        resized = np.resize(images[i,:,:,:], (img_rows, img_cols))\n",
    "        extended[i,0,:,:] = resized\n",
    "        extended[i,1,:,:] = resized\n",
    "        extended[i,2,:,:] = resized\n",
    "    return extended.astype('float32')\n",
    "\n",
    "X_trainMLO = prepare_images(trXMLO)\n",
    "X_testMLO = prepare_images(teXMLO)\n",
    "X_trainCC = prepare_images(trXCC)\n",
    "X_testCC = prepare_images(teXCC)\n",
    "\n",
    "print('X_train shape:', X_trainMLO.shape)\n",
    "print(X_trainMLO.shape[0], 'train samples')\n",
    "print(X_testMLO.shape[0], 'test samples')\n",
    "\n",
    "# Create datasets and dataloaders\n",
    "trainset = MyDataset(X_trainCC, y_trainCC, X_trainMLO, y_trainMLO)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=8, shuffle=True, num_workers=2)\n",
    "testset = MyDataset(X_testCC, y_testCC, X_testMLO, y_testMLO)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=1, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('==> Building model..')\n",
    "\n",
    "class EfficientNetBackbone(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(EfficientNetBackbone, self).__init__()\n",
    "        self.efficientnet = EfficientNet.from_pretrained('efficientnet-b0')\n",
    "        \n",
    "        # Remove the original classifier\n",
    "        self.features = nn.Sequential(*list(self.efficientnet.children())[:-1])\n",
    "        \n",
    "        # Add custom head for feature extraction\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "        \n",
    "        # Classification head\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(1280, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512, 2)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Extract features\n",
    "        features = self.features(x)\n",
    "        pooled = self.avgpool(features)\n",
    "        flattened = torch.flatten(pooled, 1)\n",
    "        \n",
    "        # Classify\n",
    "        predictions = self.classifier(flattened)\n",
    "        \n",
    "        return predictions, features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DualViewEfficientNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DualViewEfficientNet, self).__init__()\n",
    "        self.model_backbone = EfficientNetBackbone()\n",
    "        \n",
    "    def forward(self, CC, MLO):\n",
    "        CC_predict, CC_feature = self.model_backbone(CC)\n",
    "        MLO_predict, MLO_feature = self.model_backbone(MLO)\n",
    "        \n",
    "        # Calculate correlation between features\n",
    "        corr_total = 0\n",
    "        # EfficientNet features are 4D: [batch, channels, height, width]\n",
    "        for i in range(CC_feature.size(2)):  # Loop through spatial dimensions\n",
    "            for j in range(CC_feature.size(3)):\n",
    "                corr_total += corr(CC_feature[:,:,i,j], MLO_feature[:,:,i,j])\n",
    "        \n",
    "        correlation = corr_total / (CC_feature.size(2) * CC_feature.size(3))  # Average correlation\n",
    "        \n",
    "        return CC_predict, MLO_predict, correlation\n",
    "\n",
    "# Initialize model\n",
    "net = DualViewEfficientNet()\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)\n",
    "net = net.to(device)\n",
    "\n",
    "if device == 'cuda':\n",
    "    net = torch.nn.DataParallel(net)\n",
    "    cudnn.benchmark = True\n",
    "\n",
    "criterion1 = nn.CrossEntropyLoss()\n",
    "criterion2 = nn.CrossEntropyLoss(weight=weights)\n",
    "optimizer = optim.Adam(net.parameters(), lr=args.lr, weight_decay=1e-5)\n",
    "\n",
    "Loss_list = []\n",
    "Accuracy_list = []\n",
    "\n",
    "start_epoch = 0\n",
    "best_accCC = 0\n",
    "best_accMLO = 0\n",
    "best_accAVG = 0\n",
    "best_aucCC = 0\n",
    "best_aucMLO = 0\n",
    "best_aucAVG = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training function\n",
    "def train(epoch):\n",
    "    print('\\nEpoch: %d' % epoch)\n",
    "    net.train()\n",
    "    train_lossCC = 0\n",
    "    train_lossMLO = 0\n",
    "    train_losscorr = 0\n",
    "    train_losstotal = 0 \n",
    "    correctCC = 0\n",
    "    totalCC = 0\n",
    "    correctMLO = 0\n",
    "    totalMLO = 0    \n",
    "    phase_predCC = np.array([])\n",
    "    phase_labelCC = np.array([])\n",
    "    phase_predMLO = np.array([])\n",
    "    phase_labelMLO = np.array([])\n",
    "    \n",
    "    for batch_idx, (inputsCC, targetsCC, inputsMLO, targetsMLO) in enumerate(trainloader):\n",
    "        inputsCC, targetsCC = inputsCC.to(device), targetsCC.to(device)\n",
    "        inputsMLO, targetsMLO = inputsMLO.to(device), targetsMLO.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputsCC, outputsMLO, correlation = net(inputsCC, inputsMLO)\n",
    "        \n",
    "        lossCC = criterion2(outputsCC, targetsCC.long())\n",
    "        lossMLO = criterion2(outputsMLO, targetsMLO.long())\n",
    "        losscorr = correlation\n",
    "        losstotal = lossCC + lossMLO - losscorr\n",
    "        losstotal.backward(retain_graph=True)\n",
    "        optimizer.step()\n",
    "\n",
    "        train_lossCC += lossCC.item()\n",
    "        train_lossMLO += lossMLO.item()\n",
    "        train_losscorr += losscorr.item()\n",
    "        train_losstotal += losstotal.item()\n",
    "        _, predictedCC = outputsCC.max(1)\n",
    "        _, predictedMLO = outputsMLO.max(1)\n",
    "\n",
    "        totalCC += targetsCC.size(0)\n",
    "        correctCC += predictedCC.eq(targetsCC.long()).sum().item()\n",
    "        totalMLO += targetsMLO.size(0)\n",
    "        correctMLO += predictedMLO.eq(targetsMLO.long()).sum().item()\n",
    "\n",
    "        phase_predCC = np.append(phase_predCC, predictedCC.cpu().numpy())\n",
    "        phase_labelCC = np.append(phase_labelCC, targetsCC.data.cpu().numpy())\n",
    "\n",
    "        phase_predMLO = np.append(phase_predMLO, predictedMLO.cpu().numpy())\n",
    "        phase_labelMLO = np.append(phase_labelMLO, targetsMLO.data.cpu().numpy())\n",
    "\n",
    "    epoch_aucCC = roc_auc_score(phase_labelCC, phase_predCC)\n",
    "    epoch_aucMLO = roc_auc_score(phase_labelMLO, phase_predMLO)\n",
    "\n",
    "    print('trainLossCC: %.3f, trainAccuCC: %.3f%% (%d/%d)' % (train_lossCC/(batch_idx+1), 100.*correctCC/totalCC, correctCC, totalCC))\n",
    "    print('trainLossMLO: %.3f, trainAccuMLO: %.3f%% (%d/%d)' % (train_lossMLO/(batch_idx+1), 100.*correctMLO/totalMLO, correctMLO, totalMLO)) \n",
    "    print('trainepoch_aucCC: %.3f,trainepoch_aucMLO: %.3f' % (epoch_aucCC, epoch_aucMLO))\n",
    "    print('trainLosscorr: %.3f,trainLosstotal: %.3f' % (train_losscorr/(batch_idx+1), train_losstotal/(batch_idx+1)))\n",
    "    print('trainLosstotal: %.3f' % (train_losstotal/(batch_idx+1)))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing function\n",
    "def test(epoch):\n",
    "    global best_accCC, best_accMLO, best_accAVG, best_aucCC, best_aucMLO, best_aucAVG\n",
    "    print(\"best_accCC:\", best_accCC, \"best_accMLO:\", best_accMLO)\n",
    "    print(\"best_accAVG:\", best_accAVG)\n",
    "    print(\"best_aucCC:\", best_aucCC, \"best_aucMLO:\", best_aucMLO)\n",
    "    print(\"best_aucAVG:\", best_aucAVG)\n",
    "    \n",
    "    net.eval()\n",
    "    test_lossCC = 0\n",
    "    test_lossMLO = 0\n",
    "    test_losscorr = 0\n",
    "    test_losstotal = 0\n",
    "    correctCC = 0\n",
    "    correctMLO = 0\n",
    "    totalCC = 0\n",
    "    totalMLO = 0\n",
    "    phase_predCC = np.array([])\n",
    "    phase_labelCC = np.array([])\n",
    "    phase_predMLO = np.array([])\n",
    "    phase_labelMLO = np.array([])\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputsCC, targetsCC, inputsMLO, targetsMLO) in enumerate(testloader):\n",
    "            inputsCC, targetsCC = inputsCC.to(device), targetsCC.to(device)\n",
    "            inputsMLO, targetsMLO = inputsMLO.to(device), targetsMLO.to(device)\n",
    "\n",
    "            outputsCC, outputsMLO, correlation = net(inputsCC, inputsMLO)\n",
    "            lossCC = criterion1(outputsCC, targetsCC.long())\n",
    "            lossMLO = criterion1(outputsMLO, targetsMLO.long())\n",
    "            losstotal = lossCC + lossMLO \n",
    "            test_lossCC += lossCC.item()\n",
    "            test_lossMLO += lossMLO.item()\n",
    "            test_losstotal += losstotal.item()\n",
    "            _, predictedCC = outputsCC.max(1)\n",
    "            _, predictedMLO = outputsMLO.max(1)\n",
    "\n",
    "            totalCC += targetsCC.size(0)\n",
    "            correctCC += predictedCC.eq(targetsCC.long()).sum().item()\n",
    "            totalMLO += targetsMLO.size(0)\n",
    "            correctMLO += predictedMLO.eq(targetsMLO.long()).sum().item()\n",
    "\n",
    "            phase_predCC = np.append(phase_predCC, outputsCC[0,1].cpu().numpy())        \n",
    "            phase_labelCC = np.append(phase_labelCC, targetsCC.data.cpu().numpy())\n",
    "            phase_predMLO = np.append(phase_predMLO, outputsMLO[0,1].cpu().numpy())\n",
    "            phase_labelMLO = np.append(phase_labelMLO, targetsMLO.data.cpu().numpy())\n",
    "\n",
    "    epoch_aucCC = roc_auc_score(phase_labelCC, phase_predCC)\n",
    "    epoch_aucMLO = roc_auc_score(phase_labelMLO, phase_predMLO)\n",
    "    epoch_aucAVG = 0.5*(epoch_aucCC + epoch_aucMLO)\n",
    "    \n",
    "    print('testLossCC: %.3f, testAccuCC: %.3f%% (%d/%d)' % (test_lossCC/(batch_idx+1), 100.*correctCC/totalCC, correctCC, totalCC))\n",
    "    print('testLossMLO: %.3f, testAccuMLO: %.3f%% (%d/%d)' % (test_lossMLO/(batch_idx+1), 100.*correctMLO/totalMLO, correctMLO, totalMLO)) \n",
    "    print('testepoch_aucCC: %.3f,testepoch_aucMLO: %.3f,testepoch_aucAVG: %.3f' % (epoch_aucCC, epoch_aucMLO, epoch_aucAVG))\n",
    "    print('testLosstotal: %.3f' % (test_losstotal/(batch_idx+1)))\n",
    "\n",
    "    # Save checkpoint\n",
    "    accCC = 100.*correctCC/totalCC\n",
    "    accMLO = 100.*correctMLO/totalMLO\n",
    "    accAVG = 0.5*(accCC + accMLO)\n",
    "    \n",
    "    if((accAVG > best_accAVG) or (accAVG == best_accAVG and epoch_aucAVG > best_aucAVG)):\n",
    "        print('Saving...')\n",
    "        state = {\n",
    "            'net': net.state_dict(),\n",
    "            'accCC': accCC,\n",
    "            'accMLO': accMLO,\n",
    "            'accAVG': accAVG,\n",
    "            'epoch_aucCC': epoch_aucCC,\n",
    "            'epoch_aucMLO': epoch_aucMLO,\n",
    "            'epoch_aucavg': epoch_aucAVG, \n",
    "            'epoch': epoch,\n",
    "        }\n",
    "        if not os.path.isdir('checkpoint'):\n",
    "            os.mkdir('checkpoint')\n",
    "        torch.save(state, \"best.pth\")\n",
    "        best_accCC = accCC\n",
    "        best_accMLO = accMLO\n",
    "        best_accAVG = accAVG\n",
    "        best_aucCC = epoch_aucCC\n",
    "        best_aucMLO = epoch_aucMLO\n",
    "        best_aucAVG = epoch_aucAVG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "for epoch in range(start_epoch, start_epoch+500):\n",
    "    if (epoch % 30 == 0 and epoch != 0):\n",
    "        adjust_learning_rate(optimizer, decay_rate=0.9)\n",
    "    train(epoch)\n",
    "    test(epoch)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
