{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU","kaggle":{"accelerator":"none","dataSources":[{"sourceId":2061385,"sourceType":"datasetVersion","datasetId":1235472},{"sourceId":123298552,"sourceType":"kernelVersion"}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Utilization of DenseNet201 for diagnosis of breast abnormality\n\n**Abstract:** As one of the leading killers of females, breast cancer has become one of the heated research topics in the community of clinical medical science and computer science. In the clinic, mammography is a publicly accepted technique to detect early abnormalities such as masses and distortions in breast leading to cancer. Interpreting the images, however, is time-consuming and error-prone for radiologists considering artificial factors including potential fatigue. To improve radiologists’ working efficiency, we developed a semi-automatic computer-aided diagnosis system to classify mammograms into normality and abnormality and thus to ease the process of making a diagnosis of breast cancer. Through transferring deep convolutional neural network DenseNet201 on the basis of suspicious regions provided by radiologists into our system, we obtained the network we termed DenseNet201-C, which achieved a high diagnostic accuracy of 92.73%. The comparison results between our method and the other five methods show that our method achieved the highest accuracy.","metadata":{"id":"WxkzATVfb_Gt"}},{"cell_type":"code","source":"import os\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport pydicom\nimport imageio\nimport shutil\nimport tensorflow as tf\nimport numpy as np\nimport cv2\n\nfrom PIL import Image","metadata":{"id":"aPkJB82PS_i_","outputId":"6c1c4732-c30b-43e5-87eb-fe1e9eb81eb3","execution":{"iopub.status.busy":"2025-07-20T11:55:36.928859Z","iopub.execute_input":"2025-07-20T11:55:36.929238Z","iopub.status.idle":"2025-07-20T11:55:51.201602Z","shell.execute_reply.started":"2025-07-20T11:55:36.929204Z","shell.execute_reply":"2025-07-20T11:55:51.200389Z"},"trusted":true},"outputs":[{"name":"stderr","text":"2025-07-20 11:55:39.733307: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2025-07-20 11:55:39.733499: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2025-07-20 11:55:39.891072: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"def pipeline(image, label):\n    if tf.executing_eagerly():\n      opened_image = opening(image.numpy(), element)   # Apply morphological Openess\n      mask = create_binarized_mask(opened_image) # Create the Binary Mask\n      image = opened_image * mask\n    return image, label","metadata":{"execution":{"iopub.status.busy":"2025-07-20T11:56:09.864614Z","iopub.execute_input":"2025-07-20T11:56:09.865540Z","iopub.status.idle":"2025-07-20T11:56:09.872555Z","shell.execute_reply.started":"2025-07-20T11:56:09.865508Z","shell.execute_reply":"2025-07-20T11:56:09.871137Z"},"trusted":true},"outputs":[],"execution_count":4},{"cell_type":"code","source":"def scheduler(epoch, lr):\n     if epoch % 10 == 0:\n         return lr - 0.01\n     else:\n         return lr","metadata":{"execution":{"iopub.status.busy":"2025-07-20T11:56:13.418245Z","iopub.execute_input":"2025-07-20T11:56:13.418798Z","iopub.status.idle":"2025-07-20T11:56:13.425297Z","shell.execute_reply.started":"2025-07-20T11:56:13.418763Z","shell.execute_reply":"2025-07-20T11:56:13.423819Z"},"trusted":true},"outputs":[],"execution_count":5},{"cell_type":"code","source":"def evaluate(model, validation):\n  m = tf.keras.metrics.Accuracy()\n  for image, label in validation:\n      pred = model.predict(image)\n      pred = tf.constant(pred > 0.5, dtype=tf.int64)\n\n      m.update_state(pred, tf.expand_dims(label, 1))\n\n  return m.result()","metadata":{"execution":{"iopub.status.busy":"2025-07-20T11:56:15.563550Z","iopub.execute_input":"2025-07-20T11:56:15.563944Z","iopub.status.idle":"2025-07-20T11:56:15.570762Z","shell.execute_reply.started":"2025-07-20T11:56:15.563915Z","shell.execute_reply":"2025-07-20T11:56:15.569555Z"},"trusted":true},"outputs":[],"execution_count":6},{"cell_type":"code","source":"def init_model(freeze=False):\n  pretrained_model = tf.keras.applications.densenet.DenseNet201(\n        include_top=False,\n        weights='imagenet',\n        input_tensor=None,\n        input_shape=None,\n        pooling=None,\n        classes=None,\n        classifier_activation=None\n    )\n  if freeze:\n    for layer in pretrained_model.layers:\n        layer.trainable = False\n\n  last_layer = pretrained_model.get_layer('conv5_block32_concat')\n  x = tf.keras.layers.GlobalAveragePooling2D()(last_layer.output)\n  x =  tf.keras.layers.Flatten()(x)\n  x =  tf.keras.layers.Dropout(0.5)(x)\n  out = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n  out\n\n  return tf.keras.Model(pretrained_model.input, out)","metadata":{"execution":{"iopub.status.busy":"2025-07-20T11:56:18.108131Z","iopub.execute_input":"2025-07-20T11:56:18.109236Z","iopub.status.idle":"2025-07-20T11:56:18.116565Z","shell.execute_reply.started":"2025-07-20T11:56:18.109197Z","shell.execute_reply":"2025-07-20T11:56:18.115408Z"},"trusted":true},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"# Converting to PNG and saving locally\n","metadata":{}},{"cell_type":"markdown","source":"\"Creating a temporary directory where the images in PNG format will be stored","metadata":{}},{"cell_type":"code","source":"final_dir = os.path.join('/kaggle/working/AllPNGs')\nos.makedirs(final_dir, exist_ok=True)","metadata":{"execution":{"iopub.status.busy":"2025-07-20T11:56:21.414668Z","iopub.execute_input":"2025-07-20T11:56:21.415162Z","iopub.status.idle":"2025-07-20T11:56:21.421162Z","shell.execute_reply.started":"2025-07-20T11:56:21.415126Z","shell.execute_reply":"2025-07-20T11:56:21.419748Z"},"trusted":true},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":"Converting from .dcm to .png, and saving the images in the new directory.","metadata":{}},{"cell_type":"code","source":"directory = \"/kaggle/input/inbreast-dataset/INbreast Release 1.0/AllDICOMs/\"\n\nfor filename in os.listdir(directory):\n    if filename.endswith(\".dcm\"): \n        ds = pydicom.dcmread(os.path.join(directory, filename))\n        pixel_array = ds.pixel_array\n        name_parts = filename.split(\"_\")        \n        new_filename = name_parts[0]\n        output_path = f\"/kaggle/working/AllPNGs/{new_filename}.png\"\n        imageio.imwrite(output_path, pixel_array)","metadata":{"execution":{"iopub.status.busy":"2025-07-20T11:56:24.905429Z","iopub.execute_input":"2025-07-20T11:56:24.905874Z","iopub.status.idle":"2025-07-20T12:05:54.887916Z","shell.execute_reply.started":"2025-07-20T11:56:24.905842Z","shell.execute_reply":"2025-07-20T12:05:54.886302Z"},"trusted":true},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":"# Creating the class split and classes","metadata":{}},{"cell_type":"code","source":"os.listdir('/kaggle/input/inbreast-dataset/INbreast Release 1.0')","metadata":{"execution":{"iopub.status.busy":"2025-07-20T12:06:16.721060Z","iopub.execute_input":"2025-07-20T12:06:16.721566Z","iopub.status.idle":"2025-07-20T12:06:16.740910Z","shell.execute_reply.started":"2025-07-20T12:06:16.721532Z","shell.execute_reply":"2025-07-20T12:06:16.739609Z"},"trusted":true},"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"['INbreast.csv',\n 'README.txt',\n 'inbreast.pdf',\n 'PectoralMuscle',\n 'INbreast.xls',\n 'AllXML',\n 'AllDICOMs',\n 'AllROI',\n 'MedicalReports']"},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"raw_csv = pd.read_csv(\"/kaggle/input/inbreast-dataset/INbreast Release 1.0/INbreast.csv\", delimiter=';')\nraw_csv = raw_csv.rename(columns={'File Name':'FileName'})","metadata":{"execution":{"iopub.status.busy":"2025-07-20T12:06:20.367706Z","iopub.execute_input":"2025-07-20T12:06:20.368133Z","iopub.status.idle":"2025-07-20T12:06:20.409204Z","shell.execute_reply.started":"2025-07-20T12:06:20.368103Z","shell.execute_reply":"2025-07-20T12:06:20.408163Z"},"trusted":true},"outputs":[],"execution_count":11},{"cell_type":"code","source":"raw_csv_ = pd.read_csv(\"/kaggle/input/inbreast-roi-yolov8l/INBREAST-Mammography/description.csv\")\nraw_csv_ = raw_csv_.rename(columns={'File name':'FileName'})","metadata":{"execution":{"iopub.status.busy":"2025-07-20T12:06:24.406513Z","iopub.execute_input":"2025-07-20T12:06:24.406968Z","iopub.status.idle":"2025-07-20T12:06:24.426469Z","shell.execute_reply.started":"2025-07-20T12:06:24.406938Z","shell.execute_reply":"2025-07-20T12:06:24.424746Z"},"trusted":true},"outputs":[],"execution_count":12},{"cell_type":"code","source":"raw_csv.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T12:06:26.999510Z","iopub.execute_input":"2025-07-20T12:06:26.999924Z","iopub.status.idle":"2025-07-20T12:06:27.021006Z","shell.execute_reply.started":"2025-07-20T12:06:26.999897Z","shell.execute_reply":"2025-07-20T12:06:27.019811Z"}},"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"  Patient ID Patient age Laterality View  Acquisition date  FileName ACR  \\\n0    removed     removed          R   CC            201001  22678622   4   \n1    removed     removed          L   CC            201001  22678646   4   \n2    removed     removed          R  MLO            201001  22678670   4   \n3    removed     removed          L  MLO            201001  22678694   4   \n4    removed     removed          R   CC            201001  22614074   2   \n\n  Bi-Rads  \n0       1  \n1       3  \n2       1  \n3       3  \n4       5  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Patient ID</th>\n      <th>Patient age</th>\n      <th>Laterality</th>\n      <th>View</th>\n      <th>Acquisition date</th>\n      <th>FileName</th>\n      <th>ACR</th>\n      <th>Bi-Rads</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>removed</td>\n      <td>removed</td>\n      <td>R</td>\n      <td>CC</td>\n      <td>201001</td>\n      <td>22678622</td>\n      <td>4</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>removed</td>\n      <td>removed</td>\n      <td>L</td>\n      <td>CC</td>\n      <td>201001</td>\n      <td>22678646</td>\n      <td>4</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>removed</td>\n      <td>removed</td>\n      <td>R</td>\n      <td>MLO</td>\n      <td>201001</td>\n      <td>22678670</td>\n      <td>4</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>removed</td>\n      <td>removed</td>\n      <td>L</td>\n      <td>MLO</td>\n      <td>201001</td>\n      <td>22678694</td>\n      <td>4</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>removed</td>\n      <td>removed</td>\n      <td>R</td>\n      <td>CC</td>\n      <td>201001</td>\n      <td>22614074</td>\n      <td>2</td>\n      <td>5</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":13},{"cell_type":"code","source":"raw_csv['View'].value_counts()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T12:06:30.124113Z","iopub.execute_input":"2025-07-20T12:06:30.124533Z","iopub.status.idle":"2025-07-20T12:06:30.139771Z","shell.execute_reply.started":"2025-07-20T12:06:30.124503Z","shell.execute_reply":"2025-07-20T12:06:30.138332Z"}},"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"View\nMLO    206\nCC     203\nFB       1\nName: count, dtype: int64"},"metadata":{}}],"execution_count":14},{"cell_type":"markdown","source":"# Create a new dataframe thst will contain CC views ","metadata":{}},{"cell_type":"code","source":"# Filter rows where the View is 'CC'\nCC_Views = raw_csv[raw_csv['View'] == 'CC']\n\n# Optionally preview the filtered results\nprint(CC_Views.head())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T12:06:32.761004Z","iopub.execute_input":"2025-07-20T12:06:32.761522Z","iopub.status.idle":"2025-07-20T12:06:32.780824Z","shell.execute_reply.started":"2025-07-20T12:06:32.761483Z","shell.execute_reply":"2025-07-20T12:06:32.779679Z"}},"outputs":[{"name":"stdout","text":"   Patient ID Patient age Laterality View  Acquisition date  FileName ACR  \\\n0     removed     removed          R   CC            201001  22678622   4   \n1     removed     removed          L   CC            201001  22678646   4   \n4     removed     removed          R   CC            201001  22614074   2   \n5     removed     removed          L   CC            201001  22614097   2   \n10    removed     removed          L   CC            201001  50997488   3   \n\n   Bi-Rads  \n0        1  \n1        3  \n4        5  \n5        2  \n10       2  \n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"CC_Views.value_counts()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T12:06:36.406397Z","iopub.execute_input":"2025-07-20T12:06:36.406881Z","iopub.status.idle":"2025-07-20T12:06:36.430644Z","shell.execute_reply.started":"2025-07-20T12:06:36.406852Z","shell.execute_reply":"2025-07-20T12:06:36.429537Z"}},"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"Patient ID  Patient age  Laterality  View  Acquisition date  FileName  ACR  Bi-Rads\nremoved     removed      L           CC    200801            24055483  1    4c         1\n                         R           CC    200902            20588164  2    1          1\n                                           200901            51070197  2    2          1\n                                                             53582818  2    2          1\n                                           200902            20586908  2    2          1\n                                                                                      ..\n                         L           CC    201001            50993841  3    2          1\n                                                             50994787  3    1          1\n                                                             50996110  1    2          1\n                                                             50996228  4    2          1\n                         R           CC    201001            53587663  1    2          1\nName: count, Length: 203, dtype: int64"},"metadata":{}}],"execution_count":16},{"cell_type":"code","source":"print(CC_Views['Bi-Rads'].value_counts())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T12:22:23.188608Z","iopub.execute_input":"2025-07-20T12:22:23.189837Z","iopub.status.idle":"2025-07-20T12:22:23.199816Z","shell.execute_reply.started":"2025-07-20T12:22:23.189796Z","shell.execute_reply":"2025-07-20T12:22:23.198422Z"}},"outputs":[{"name":"stdout","text":"Bi-Rads\n2     109\n1      33\n5      24\n3      11\n4c     11\n4a      7\n6       4\n4b      4\nName: count, dtype: int64\n","output_type":"stream"}],"execution_count":27},{"cell_type":"code","source":"# Map BI-RADS to binary labels (benign: 1,2,3; malignant: 4,5,6)\nCC_Views = CC_Views.copy()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T12:23:16.836408Z","iopub.execute_input":"2025-07-20T12:23:16.836910Z","iopub.status.idle":"2025-07-20T12:23:16.853187Z","shell.execute_reply.started":"2025-07-20T12:23:16.836878Z","shell.execute_reply":"2025-07-20T12:23:16.851550Z"}},"outputs":[{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"Label\n1    203\nName: count, dtype: int64"},"metadata":{}}],"execution_count":28},{"cell_type":"code","source":"# Clean Bi-Rads column: convert strings like '4a', '4b', '4c' to numeric 4\ndef clean_birads(value):\n    if isinstance(value, str):\n        # Extract the numeric part (e.g., '4a' -> '4', '4c' -> '4')\n        value = ''.join(filter(str.isdigit, value))\n    try:\n        return int(value)\n    except (ValueError, TypeError):\n        return np.nan  # Handle invalid entries as NaN","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T12:36:33.833848Z","iopub.execute_input":"2025-07-20T12:36:33.834277Z","iopub.status.idle":"2025-07-20T12:36:33.840809Z","shell.execute_reply.started":"2025-07-20T12:36:33.834249Z","shell.execute_reply":"2025-07-20T12:36:33.839517Z"}},"outputs":[],"execution_count":31},{"cell_type":"code","source":"CC_Views['Bi-Rads_Cleaned'] = CC_Views['Bi-Rads'].apply(clean_birads)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T12:36:53.984340Z","iopub.execute_input":"2025-07-20T12:36:53.985363Z","iopub.status.idle":"2025-07-20T12:36:53.992830Z","shell.execute_reply.started":"2025-07-20T12:36:53.985293Z","shell.execute_reply":"2025-07-20T12:36:53.991389Z"}},"outputs":[],"execution_count":32},{"cell_type":"code","source":"\n# Check for NaN values after cleaning\nprint(\"NaN values in Bi-Rads_Cleaned:\", CC_Views['Bi-Rads_Cleaned'].isna().sum())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T12:37:06.484828Z","iopub.execute_input":"2025-07-20T12:37:06.485267Z","iopub.status.idle":"2025-07-20T12:37:06.492737Z","shell.execute_reply.started":"2025-07-20T12:37:06.485237Z","shell.execute_reply":"2025-07-20T12:37:06.491368Z"}},"outputs":[{"name":"stdout","text":"NaN values in Bi-Rads_Cleaned: 0\n","output_type":"stream"}],"execution_count":33},{"cell_type":"code","source":"\n# Map BI-RADS to binary labels (benign: 1,2,3; malignant: 4,5,6)\nCC_Views['Label'] = CC_Views['Bi-Rads_Cleaned'].apply(lambda x: 0 if x in [1, 2, 3] else 1)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T12:37:26.870382Z","iopub.execute_input":"2025-07-20T12:37:26.871569Z","iopub.status.idle":"2025-07-20T12:37:26.877722Z","shell.execute_reply.started":"2025-07-20T12:37:26.871525Z","shell.execute_reply":"2025-07-20T12:37:26.876191Z"}},"outputs":[],"execution_count":34},{"cell_type":"code","source":"CC_Views.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T12:38:13.683789Z","iopub.execute_input":"2025-07-20T12:38:13.684202Z","iopub.status.idle":"2025-07-20T12:38:13.699940Z","shell.execute_reply.started":"2025-07-20T12:38:13.684175Z","shell.execute_reply":"2025-07-20T12:38:13.698771Z"}},"outputs":[{"execution_count":36,"output_type":"execute_result","data":{"text/plain":"   Patient ID Patient age Laterality View  Acquisition date          FileName  \\\n0     removed     removed          R   CC            201001  22678622.png.png   \n1     removed     removed          L   CC            201001  22678646.png.png   \n4     removed     removed          R   CC            201001  22614074.png.png   \n5     removed     removed          L   CC            201001  22614097.png.png   \n10    removed     removed          L   CC            201001  50997488.png.png   \n\n   ACR Bi-Rads  Label  Bi-Rads_Cleaned  \n0    4       1      0                1  \n1    4       3      0                3  \n4    2       5      1                5  \n5    2       2      0                2  \n10   3       2      0                2  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Patient ID</th>\n      <th>Patient age</th>\n      <th>Laterality</th>\n      <th>View</th>\n      <th>Acquisition date</th>\n      <th>FileName</th>\n      <th>ACR</th>\n      <th>Bi-Rads</th>\n      <th>Label</th>\n      <th>Bi-Rads_Cleaned</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>removed</td>\n      <td>removed</td>\n      <td>R</td>\n      <td>CC</td>\n      <td>201001</td>\n      <td>22678622.png.png</td>\n      <td>4</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>removed</td>\n      <td>removed</td>\n      <td>L</td>\n      <td>CC</td>\n      <td>201001</td>\n      <td>22678646.png.png</td>\n      <td>4</td>\n      <td>3</td>\n      <td>0</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>removed</td>\n      <td>removed</td>\n      <td>R</td>\n      <td>CC</td>\n      <td>201001</td>\n      <td>22614074.png.png</td>\n      <td>2</td>\n      <td>5</td>\n      <td>1</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>removed</td>\n      <td>removed</td>\n      <td>L</td>\n      <td>CC</td>\n      <td>201001</td>\n      <td>22614097.png.png</td>\n      <td>2</td>\n      <td>2</td>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>removed</td>\n      <td>removed</td>\n      <td>L</td>\n      <td>CC</td>\n      <td>201001</td>\n      <td>50997488.png.png</td>\n      <td>3</td>\n      <td>2</td>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":36},{"cell_type":"code","source":"print(\"Sample of cleaned data:\\n\", CC_Views[['FileName', 'Bi-Rads', 'Bi-Rads_Cleaned', 'Label']].head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T12:47:41.934168Z","iopub.execute_input":"2025-07-20T12:47:41.935685Z","iopub.status.idle":"2025-07-20T12:47:41.948302Z","shell.execute_reply.started":"2025-07-20T12:47:41.935638Z","shell.execute_reply":"2025-07-20T12:47:41.946487Z"}},"outputs":[{"name":"stdout","text":"Sample of cleaned data:\n             FileName Bi-Rads  Bi-Rads_Cleaned  Label\n0   22678622.png.png       1                1      0\n1   22678646.png.png       3                3      0\n4   22614074.png.png       5                5      1\n5   22614097.png.png       2                2      0\n10  50997488.png.png       2                2      0\n","output_type":"stream"}],"execution_count":37},{"cell_type":"code","source":"CC_Views['Label'].value_counts()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T12:49:52.171958Z","iopub.execute_input":"2025-07-20T12:49:52.172740Z","iopub.status.idle":"2025-07-20T12:49:52.181227Z","shell.execute_reply.started":"2025-07-20T12:49:52.172708Z","shell.execute_reply":"2025-07-20T12:49:52.180135Z"}},"outputs":[{"execution_count":41,"output_type":"execute_result","data":{"text/plain":"Label\n0    153\n1     50\nName: count, dtype: int64"},"metadata":{}}],"execution_count":41},{"cell_type":"code","source":" \n# Prepare image paths and labels\nCC_Views['FileName'] = CC_Views['FileName'].astype(str) + \".png\"\nimage_paths = [os.path.join(output_dir, fname) for fname in CC_Views['FileName']]\nlabels = CC_Views['Label'].values","metadata":{"trusted":true,"execution":{"execution_failed":"2025-07-20T14:18:40.464Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Step 1: Split dataset into train (70%), validation (20%), and test (10%)\n# First split: 70% train, 30% temp (val + test)\ntrain_paths, temp_paths, train_labels, temp_labels = train_test_split(\n    image_paths, labels, test_size=0.3, random_state=42, stratify=labels\n)\n# Second split: 20% validation (2/3 of temp), 10% test (1/3 of temp)\nval_paths, test_paths, val_labels, test_labels = train_test_split(\n    temp_paths, temp_labels, test_size=0.333, random_state=42, stratify=temp_labels\n)","metadata":{"trusted":true,"execution":{"execution_failed":"2025-07-20T14:18:40.465Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Verify split sizes\nprint(f\"Train set: {len(train_paths)} samples\")\nprint(f\"Validation set: {len(val_paths)} samples\")\nprint(f\"Test set: {len(test_paths)} samples\")","metadata":{"trusted":true,"execution":{"execution_failed":"2025-07-20T14:18:40.465Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Step 2: Balance the training set using SMOTE\n# SMOTE requires numerical features, so we use indices and resample paths/labels\n# Explanation: The original training set is imbalanced (approx. 107 benign, 35 malignant).\n# SMOTE generates synthetic samples for the minority class (malignant) by interpolating\n# between existing samples, balancing the classes to have equal counts (approx. 107 each).\ntrain_indices = np.arange(len(train_paths)).reshape(-1, 1)\nsmote = SMOTE(random_state=42)\ntrain_indices_resampled, train_labels_resampled = smote.fit_resample(train_indices, train_labels)\n# Map resampled indices back to paths\ntrain_paths_resampled = [train_paths[i[0]] for i in train_indices_resampled]","metadata":{"trusted":true,"execution":{"execution_failed":"2025-07-20T14:18:40.466Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Verify balanced training set\nprint(\"Balanced training label distribution:\\n\", pd.Series(train_labels_resampled).value_counts())","metadata":{"trusted":true,"execution":{"execution_failed":"2025-07-20T14:18:40.466Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Morphological opening and mask creation\ndef opening(image, element=np.ones((5, 5))):\n    return morphology.grey_opening(image, structure=element)\n\ndef create_binarized_mask(image):\n    _, binary = cv2.threshold(image, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n    return binary / 255.0\n\n# Image preprocessing pipeline\ndef pipeline(image, label):\n    if tf.executing_eagerly():\n        opened_image = opening(image.numpy(), np.ones((5, 5)))\n        mask = create_binarized_mask(opened_image)\n        image = opened_image * mask\n    return image, label\n\ndef tf_pipeline(image, label):\n    [image, label] = tf.py_function(pipeline, [image, label], [tf.float32, tf.int32])\n    image.set_shape([None, None, 3])\n    label.set_shape([])\n    return image, label","metadata":{"trusted":true,"execution":{"execution_failed":"2025-07-20T14:18:40.466Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"Load and preprocess images\ndef load_image(path, label):\n    image = tf.io.read_file(path)\n    image = tf.image.decode_png(image, channels=3)\n    image = tf.image.resize(image, [224, 224])\n    image = image / 255.0\n    return image, label\n\n# Create TensorFlow datasets\ntrain_dataset = tf.data.Dataset.from_tensor_slices((train_paths_resampled, train_labels_resampled))\nval_dataset = tf.data.Dataset.from_tensor_slices((val_paths, val_labels))\ntest_dataset = tf.data.Dataset.from_tensor_slices((test_paths, test_labels))\n\ntrain_dataset = (train_dataset\n                 .map(load_image, num_parallel_calls=tf.data.AUTOTUNE)\n                 .map(tf_pipeline, num_parallel_calls=tf.data.AUTOTUNE)\n                 .batch(16)\n                 .prefetch(tf.data.AUTOTUNE))\n\nval_dataset = (val_dataset\n               .map(load_image, num_parallel_calls=tf.data.AUTOTUNE)\n               .map(tf_pipeline, num_parallel_calls=tf.data.AUTOTUNE)\n               .batch(16)\n               .prefetch(tf.data.AUTOTUNE))\n\ntest_dataset = (test_dataset\n                .map(load_image, num_parallel_calls=tf.data.AUTOTUNE)\n                .map(tf_pipeline, num_parallel_calls=tf.data.AUTOTUNE)\n                .batch(16)\n                .prefetch(tf.data.AUTOTUNE))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Learning rate scheduler\ndef scheduler(epoch, lr):\n    if epoch % 10 == 0:\n        return max(lr - 0.01, 0.0001)\n    return lr\n\n# Initialize DenseNet201 model\ndef init_model(freeze=False):\n    pretrained_model = tf.keras.applications.densenet.DenseNet201(\n        include_top=False,\n        weights='imagenet',\n        input_shape=(224, 224, 3)\n    )\n    if freeze:\n        for layer in pretrained_model.layers:\n            layer.trainable = False\n    last_layer = pretrained_model.get_layer('conv5_block32_concat')\n    x = tf.keras.layers.GlobalAveragePooling2D()(last_layer.output)\n    x = tf.keras.layers.Flatten()(x)\n    x = tf.keras.layers.Dropout(0.5)(x)\n    out = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n    return tf.keras.Model(pretrained_model.input, out)\n\n# Evaluation function\ndef evaluate(model, dataset):\n    m = tf.keras.metrics.BinaryAccuracy()\n    for image, label in dataset:\n        pred = model.predict(image)\n        pred = tf.constant(pred > 0.5, dtype=tf.float32)\n        m.update_state(pred, tf.cast(tf.expand_dims(label, 1), tf.float32))\n    return m.result().numpy()\n\n# Initialize and compile model\nmodel = init_model(freeze=True)\nmodel.compile(\n    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n    loss='binary_crossentropy',\n    metrics=['binary_accuracy']\n)\n\n# Learning rate callback\nlr_callback = tf.keras.callbacks.LearningRateScheduler(scheduler)\n\n# Train model\nmodel.fit(\n    train_dataset,\n    validation_data=val_dataset,\n    epochs=30,\n    callbacks=[lr_callback]\n)\n\n# Evaluate on validation and test sets\nval_accuracy = evaluate(model, val_dataset)\ntest_accuracy = evaluate(model, test_dataset)\nprint(f\"Validation Binary Accuracy: {val_accuracy:.4f}\")\nprint(f\"Test Binary Accuracy: {test_accuracy:.4f}\")\n\n# Save model\nmodel.save('/kaggle/working/cc_view_classifier_balanced.h5')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n\n# Split dataset\ntrain_paths, val_paths, train_labels, val_labels = train_test_split(\n    image_paths, labels, test_size=0.2, random_state=42, stratify=labels\n)\n\n# Morphological opening and mask creation\ndef opening(image, element=np.ones((5, 5))):\n    return morphology.grey_opening(image, structure=element)\n\ndef create_binarized_mask(image):\n    _, binary = cv2.threshold(image, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n    return binary / 255.0\n\n# Image preprocessing pipeline\ndef pipeline(image, label):\n    if tf.executing_eagerly():\n        opened_image = opening(image.numpy(), np.ones((5, 5)))\n        mask = create_binarized_mask(opened_image)\n        image = opened_image * mask\n    return image, label\n\n# Wrap pipeline for TensorFlow\ndef tf_pipeline(image, label):\n    [image, label] = tf.py_function(pipeline, [image, label], [tf.float32, tf.int32])\n    image.set_shape([None, None, 3])\n    label.set_shape([])\n    return image, label\n\n# Load and preprocess images\ndef load_image(path, label):\n    image = tf.io.read_file(path)\n    image = tf.image.decode_png(image, channels=3)\n    image = tf.image.resize(image, [224, 224])\n    image = image / 255.0  # Normalize to [0,1]\n    return image, label\n\n# Create TensorFlow datasets\ntrain_dataset = tf.data.Dataset.from_tensor_slices((train_paths, train_labels))\nval_dataset = tf.data.Dataset.from_tensor_slices((val_paths, val_labels))\n\ntrain_dataset = (train_dataset\n                 .map(load_image, num_parallel_calls=tf.data.AUTOTUNE)\n                 .map(tf_pipeline, num_parallel_calls=tf.data.AUTOTUNE)\n                 .batch(16)\n                 .prefetch(tf.data.AUTOTUNE))\n\nval_dataset = (val_dataset\n               .map(load_image, num_parallel_calls=tf.data.AUTOTUNE)\n               .map(tf_pipeline, num_parallel_calls=tf.data.AUTOTUNE)\n               .batch(16)\n               .prefetch(tf.data.AUTOTUNE))\n\n# Learning rate scheduler\ndef scheduler(epoch, lr):\n    if epoch % 10 == 0:\n        return max(lr - 0.01, 0.0001)\n    return lr\n\n# Initialize model\ndef init_model(freeze=False):\n    pretrained_model = tf.keras.applications.densenet.DenseNet201(\n        include_top=False,\n        weights='imagenet',\n        input_shape=(224, 224, 3)\n    )\n    if freeze:\n        for layer in pretrained_model.layers:\n            layer.trainable = False\n    last_layer = pretrained_model.get_layer('conv5_block32_concat')\n    x = tf.keras.layers.GlobalAveragePooling2D()(last_layer.output)\n    x = tf.keras.layers.Flatten()(x)\n    x = tf.keras.layers.Dropout(0.5)(x)\n    out = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n    return tf.keras.Model(pretrained_model.input, out)\n\n# Evaluation function\ndef evaluate(model, validation):\n    m = tf.keras.metrics.BinaryAccuracy()\n    for image, label in validation:\n        pred = model.predict(image)\n        pred = tf.constant(pred > 0.5, dtype=tf.float32)\n        m.update_state(pred, tf.cast(tf.expand_dims(label, 1), tf.float32))\n    return m.result().numpy()\n\n# Initialize and compile model\nmodel = init_model(freeze=True)\nmodel.compile(\n    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n    loss='binary_crossentropy',\n    metrics=['binary_accuracy']\n)\n\n# Learning rate callback\nlr_callback = tf.keras.callbacks.LearningRateScheduler(scheduler)\n\n# Train model\nmodel.fit(\n    train_dataset,\n    validation_data=val_dataset,\n    epochs=30,\n    callbacks=[lr_callback]\n)\n\n# Evaluate model\naccuracy = evaluate(model, val_dataset)\nprint(f\"Validation Binary Accuracy: {accuracy:.4f}\")\n\n# Save model\nmodel.save('/kaggle/working/cc_view_classifier.h5')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T12:13:55.757713Z","iopub.execute_input":"2025-07-20T12:13:55.758072Z","iopub.status.idle":"2025-07-20T12:14:31.857952Z","shell.execute_reply.started":"2025-07-20T12:13:55.758048Z","shell.execute_reply":"2025-07-20T12:14:31.856142Z"}},"outputs":[{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/densenet/densenet201_weights_tf_dim_ordering_tf_kernels_notop.h5\n\u001b[1m74836368/74836368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 0us/step\nEpoch 1/30\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)","Cell \u001b[0;32mIn[24], line 100\u001b[0m\n\u001b[1;32m     97\u001b[0m lr_callback \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mLearningRateScheduler(scheduler)\n\u001b[1;32m     99\u001b[0m \u001b[38;5;66;03m# Train model\u001b[39;00m\n\u001b[0;32m--> 100\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    101\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    102\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    103\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    104\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mlr_callback\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    105\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;66;03m# Evaluate model\u001b[39;00m\n\u001b[1;32m    108\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m evaluate(model, val_dataset)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n","\u001b[0;31mNotFoundError\u001b[0m: Graph execution error:\n\nDetected at node ReadFile defined at (most recent call last):\n<stack traces unavailable>\n/kaggle/working/AllPNGs/53587663.png.png; No such file or directory\n\t [[{{node ReadFile}}]]\n\t [[IteratorGetNext]] [Op:__inference_one_step_on_iterator_35177]"],"ename":"NotFoundError","evalue":"Graph execution error:\n\nDetected at node ReadFile defined at (most recent call last):\n<stack traces unavailable>\n/kaggle/working/AllPNGs/53587663.png.png; No such file or directory\n\t [[{{node ReadFile}}]]\n\t [[IteratorGetNext]] [Op:__inference_one_step_on_iterator_35177]","output_type":"error"}],"execution_count":24},{"cell_type":"markdown","source":"# Create a new df with MLO views Images ","metadata":{}},{"cell_type":"code","source":"# Filter rows where the View is 'CC'\nMLO_Views = raw_csv[raw_csv['View'] == 'MLO']\n\n# Optionally preview the filtered results\nprint(MLO_Views.head())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-18T06:24:05.728084Z","iopub.execute_input":"2025-07-18T06:24:05.728457Z","iopub.status.idle":"2025-07-18T06:24:05.738286Z","shell.execute_reply.started":"2025-07-18T06:24:05.728432Z","shell.execute_reply":"2025-07-18T06:24:05.737074Z"}},"outputs":[{"name":"stdout","text":"  Patient ID Patient age Laterality View  Acquisition date  FileName ACR  \\\n2    removed     removed          R  MLO            201001  22678670   4   \n3    removed     removed          L  MLO            201001  22678694   4   \n6    removed     removed          R  MLO            201001  22614127   2   \n7    removed     removed          L  MLO            201001  22614150   2   \n8    removed     removed          L  MLO            201001  50997434   3   \n\n  Bi-Rads  \n2       1  \n3       3  \n6       5  \n7       2  \n8       2  \n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"MLO_Views.value_counts()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-18T07:01:58.423982Z","iopub.execute_input":"2025-07-18T07:01:58.424405Z","iopub.status.idle":"2025-07-18T07:01:58.442586Z","shell.execute_reply.started":"2025-07-18T07:01:58.424376Z","shell.execute_reply":"2025-07-18T07:01:58.441506Z"}},"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"Patient ID  Patient age  Laterality  View  Acquisition date  FileName  ACR  Bi-Rads\nremoved     removed      L           MLO   200801            24055445  1    4c         1\n                         R           MLO   200902            20588046  3    6          1\n                                           200901            51049655  2    2          1\n                                                             53582710  2    2          1\n                                                             53582764  2    2          1\n                                                                                      ..\n                         L           MLO   201001            50993787  3    2          1\n                                                             50994733  3    1          1\n                                                             50996056  1    2          1\n                                                             50996201  4    2          1\n                         R           MLO   201001            53587717  1    2          1\nName: count, Length: 206, dtype: int64"},"metadata":{}}],"execution_count":22},{"cell_type":"code","source":"# class mapper I-RADS scores of 1 to 3 were mapped as Benign (0), while scores of 4 to 6 were assignedas Malignant (1) as shown","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"raw_csv = pd.merge(\n    raw_csv,\n    raw_csv_[['FileName','Lesion annotation status']],\n    how='left',\n    on = 'FileName'\n)","metadata":{"execution":{"iopub.status.busy":"2024-05-29T17:25:37.982158Z","iopub.execute_input":"2024-05-29T17:25:37.982695Z","iopub.status.idle":"2024-05-29T17:25:38.001235Z","shell.execute_reply.started":"2024-05-29T17:25:37.982665Z","shell.execute_reply":"2024-05-29T17:25:38.00049Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data_info = raw_csv.copy()","metadata":{"execution":{"iopub.status.busy":"2024-05-29T17:25:38.002345Z","iopub.execute_input":"2024-05-29T17:25:38.002879Z","iopub.status.idle":"2024-05-29T17:25:38.008282Z","shell.execute_reply.started":"2024-05-29T17:25:38.002856Z","shell.execute_reply":"2024-05-29T17:25:38.007374Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"ALL_CLASSES = data_info['Lesion annotation status']\nABNORMAL_CLASSES = ALL_CLASSES !='NO ANNOTATION (NORMAL)'\nabnormal_images = data_info[ABNORMAL_CLASSES]\ndata_info.loc[ABNORMAL_CLASSES, [\"NEW_CLASS\"]] = [\"ABNORM\"] * abnormal_images.shape[0]\ndata_info[\"NEW_CLASS\"] = data_info[\"NEW_CLASS\"].fillna(\"NORM\")\ndata_info = data_info.drop(columns=['Lesion annotation status'])","metadata":{"id":"_4o--Lc8kvB8","outputId":"0f8c87a0-ec3d-454a-d057-534132e0f8ec","execution":{"iopub.status.busy":"2024-05-29T17:25:38.009409Z","iopub.execute_input":"2024-05-29T17:25:38.009689Z","iopub.status.idle":"2024-05-29T17:25:38.023226Z","shell.execute_reply.started":"2024-05-29T17:25:38.009667Z","shell.execute_reply":"2024-05-29T17:25:38.022484Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"IMAGE_DIR = \"/kaggle/working/AllPNGs/\"\nSAVE_DIR = \"inbreast\"\nclass_list = ['NORM', 'ABNORM']\nfor class_name in class_list:\n  final_dir = os.path.join(SAVE_DIR, class_name)\n  os.makedirs(final_dir, exist_ok=True)\n\n\nfor refnum, class_name in data_info.loc[:, ['FileName','NEW_CLASS']].values:\n    in_filename = f\"{refnum}.png\"\n    out_filename = f\"{refnum}.png\"\n   \n    img_png = Image.open(os.path.join(IMAGE_DIR, in_filename)).convert(\"RGB\")\n    final_dir = os.path.join(SAVE_DIR, class_name)\n\n    img_png.save(os.path.join(final_dir, out_filename))\n    # shutil.copyfile(os.path.join(IMAGE_DIR, filename),\n    #                 os.path.join(final_dir, out_filename))\n","metadata":{"id":"uNLhKIn_8VBS","execution":{"iopub.status.busy":"2024-05-29T17:25:38.02428Z","iopub.execute_input":"2024-05-29T17:25:38.024589Z","iopub.status.idle":"2024-05-29T17:29:49.775273Z","shell.execute_reply.started":"2024-05-29T17:25:38.024558Z","shell.execute_reply":"2024-05-29T17:29:49.774476Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data_augmentation = tf.keras.Sequential([\n  tf.keras.layers.RandomFlip(\"horizontal_and_vertical\"),\n  tf.keras.layers.RandomRotation((0, 1)),\n])","metadata":{"id":"Q9yQCK1xFhrv","execution":{"iopub.status.busy":"2024-05-29T17:29:49.776549Z","iopub.execute_input":"2024-05-29T17:29:49.776984Z","iopub.status.idle":"2024-05-29T17:29:50.39152Z","shell.execute_reply.started":"2024-05-29T17:29:49.776948Z","shell.execute_reply":"2024-05-29T17:29:50.390729Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"directory = \"/kaggle/working/inbreast\"\nfor dir in os.listdir(directory):\n  new_path = os.path.join(directory, dir)\n\n  if dir == \"ABNORM\":\n    for example in os.listdir(new_path):\n        example_path = os.path.join(new_path, example)\n        img_example = Image.open(example_path).convert(\"RGB\")\n        augmented_image = data_augmentation(np.asarray(img_example))\n        out_filename = \"aug_\" + example\n\n        cv2.imwrite(os.path.join(new_path, out_filename), augmented_image.numpy())\n      #Image.save(, )\n","metadata":{"id":"PppiBRetD2YH","execution":{"iopub.status.busy":"2024-05-29T17:29:50.395635Z","iopub.execute_input":"2024-05-29T17:29:50.396279Z","iopub.status.idle":"2024-05-29T17:33:36.611484Z","shell.execute_reply.started":"2024-05-29T17:29:50.396251Z","shell.execute_reply":"2024-05-29T17:33:36.610648Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"training_data, validation_data = tf.keras.utils.image_dataset_from_directory(\n    directory,\n    labels=\"inferred\",\n    label_mode=\"int\",\n    class_names=None,\n    color_mode=\"rgb\",\n    batch_size=8,\n    image_size=(224, 224),\n    shuffle=True,\n    seed=42,\n    validation_split=0.2,\n    subset=\"both\",\n    interpolation=\"bilinear\",\n)","metadata":{"id":"PENJ2bEB9Gun","outputId":"222b28ee-b55d-491a-f464-fb63ec7430ca","execution":{"iopub.status.busy":"2024-05-29T17:33:36.612495Z","iopub.execute_input":"2024-05-29T17:33:36.61276Z","iopub.status.idle":"2024-05-29T17:33:37.985742Z","shell.execute_reply.started":"2024-05-29T17:33:36.612738Z","shell.execute_reply":"2024-05-29T17:33:37.984718Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"training_dataset = training_data.map(pipeline)\nvalidation_dataset = validation_data.map(pipeline)","metadata":{"id":"I6cdD8QAf3OI","execution":{"iopub.status.busy":"2024-05-29T17:33:37.986986Z","iopub.execute_input":"2024-05-29T17:33:37.987359Z","iopub.status.idle":"2024-05-29T17:33:38.072321Z","shell.execute_reply.started":"2024-05-29T17:33:37.987327Z","shell.execute_reply":"2024-05-29T17:33:38.07162Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"tf_scheduler = tf.keras.callbacks.LearningRateScheduler(scheduler)","metadata":{"execution":{"iopub.status.busy":"2024-05-29T17:33:38.073697Z","iopub.execute_input":"2024-05-29T17:33:38.074077Z","iopub.status.idle":"2024-05-29T17:33:38.07822Z","shell.execute_reply.started":"2024-05-29T17:33:38.074044Z","shell.execute_reply":"2024-05-29T17:33:38.077348Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Resultados com freeze=False","metadata":{}},{"cell_type":"code","source":"accs = []\nfor i in range(5):\n  model = init_model(freeze=False)\n  model.compile(\n    loss=tf.keras.losses.binary_crossentropy ,\n    optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n    metrics=['acc'],\n\n  )\n  history = model.fit(\n      training_dataset,\n      epochs=5,\n      verbose = 1,\n  )\n  result = evaluate(model, validation_dataset)\n  accs.append(result)\n  print(\"Accuracy: \", result)","metadata":{"id":"2u5NeQEw10GZ","outputId":"16d54089-77f0-4871-bd18-efe9b7823cf6","execution":{"iopub.status.busy":"2024-05-29T16:23:14.074179Z","iopub.execute_input":"2024-05-29T16:23:14.07445Z","iopub.status.idle":"2024-05-29T17:11:55.475338Z","shell.execute_reply.started":"2024-05-29T16:23:14.074418Z","shell.execute_reply":"2024-05-29T17:11:55.474326Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"np.mean(accs).round(6), np.std(accs).round(6), np.median(accs).round(6)","metadata":{"execution":{"iopub.status.busy":"2024-05-29T17:13:42.937682Z","iopub.execute_input":"2024-05-29T17:13:42.938277Z","iopub.status.idle":"2024-05-29T17:13:42.946388Z","shell.execute_reply.started":"2024-05-29T17:13:42.938247Z","shell.execute_reply":"2024-05-29T17:13:42.945337Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"np.std(accs)","metadata":{"execution":{"iopub.status.busy":"2024-05-29T17:14:03.499637Z","iopub.execute_input":"2024-05-29T17:14:03.499986Z","iopub.status.idle":"2024-05-29T17:14:03.507107Z","shell.execute_reply.started":"2024-05-29T17:14:03.499961Z","shell.execute_reply":"2024-05-29T17:14:03.506061Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Resultados com freeze=True","metadata":{"execution":{"iopub.status.busy":"2024-05-27T23:13:37.344875Z","iopub.status.idle":"2024-05-27T23:13:37.345193Z","shell.execute_reply.started":"2024-05-27T23:13:37.345032Z","shell.execute_reply":"2024-05-27T23:13:37.345051Z"}}},{"cell_type":"code","source":"accs_freeze = []\nfor i in range(5):\n  model = init_model(freeze=True)\n  model.compile(\n    loss=tf.keras.losses.binary_crossentropy ,\n    optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n    metrics=['acc'],\n\n  )\n  history = model.fit(\n      training_dataset ,\n      epochs=5,\n      verbose = 1,\n  )\n  result = evaluate(model, validation_dataset)\n  accs_freeze.append(result)\n  print(\"Accuracy: \", result)","metadata":{"execution":{"iopub.status.busy":"2024-05-29T17:33:38.079197Z","iopub.execute_input":"2024-05-29T17:33:38.079469Z","iopub.status.idle":"2024-05-29T17:49:10.880808Z","shell.execute_reply.started":"2024-05-29T17:33:38.079447Z","shell.execute_reply":"2024-05-29T17:49:10.87979Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"np.mean(accs_freeze).round(3), np.std(accs_freeze).round(3), np.median(accs_freeze).round(3)","metadata":{"execution":{"iopub.status.busy":"2024-05-29T17:49:10.882579Z","iopub.execute_input":"2024-05-29T17:49:10.883452Z","iopub.status.idle":"2024-05-29T17:49:10.892858Z","shell.execute_reply.started":"2024-05-29T17:49:10.883411Z","shell.execute_reply":"2024-05-29T17:49:10.891773Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"np.std(accs_freeze)","metadata":{"execution":{"iopub.status.busy":"2024-05-29T17:49:10.894078Z","iopub.execute_input":"2024-05-29T17:49:10.894457Z","iopub.status.idle":"2024-05-29T17:49:10.904472Z","shell.execute_reply.started":"2024-05-29T17:49:10.894424Z","shell.execute_reply":"2024-05-29T17:49:10.903648Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{},"outputs":[],"execution_count":null}]}